{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_T_STEPS = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get adjacency matrix for our partitions of Jurbey map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graph_utils import partition_graph_by_lonlat\n",
    "import networkx as nx\n",
    "from jurbey.jurbey import JURBEY\n",
    "\n",
    "with open(\"../data/1556798416403.jurbey\", 'rb') as tempf:\n",
    "    g = JURBEY.load(tempf.read())\n",
    "    \n",
    "g_partition = partition_graph_by_lonlat(g)\n",
    "\n",
    "A = nx.adjacency_matrix(g_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert timeseries raw data into sparse tensor\n",
    "Tensor size: 144 timestamps by adjacency matrix of speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"../data/timeseries_speed_april_first_week.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>9.136869</td>\n",
       "      <td>11.530145</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>9.136869</td>\n",
       "      <td>11.530145</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.285511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>16.631804</td>\n",
       "      <td>11.133786</td>\n",
       "      <td>7.663071</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>27537239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.033088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873969</td>\n",
       "      <td>12.137977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.890066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.178754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>26908815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.952773</td>\n",
       "      <td>20.377332</td>\n",
       "      <td>9.472034</td>\n",
       "      <td>7.588203</td>\n",
       "      <td>9.702233</td>\n",
       "      <td>6.167263</td>\n",
       "      <td>5.860414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.705081</td>\n",
       "      <td>9.684380</td>\n",
       "      <td>29.012508</td>\n",
       "      <td>14.253002</td>\n",
       "      <td>8.932515</td>\n",
       "      <td>6.764400</td>\n",
       "      <td>10.154796</td>\n",
       "      <td>10.821180</td>\n",
       "      <td>628154370</td>\n",
       "      <td>3804638178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   0   1          2          3          4          5  \\\n",
       "0  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "1  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "2  result.average NaN NaN  18.285511        NaN        NaN  10.486210   \n",
       "3  result.average NaN NaN        NaN        NaN  19.033088        NaN   \n",
       "4  result.average NaN NaN  10.952773  20.377332   9.472034   7.588203   \n",
       "\n",
       "           6          7          8  ...       136        137        138  \\\n",
       "0   6.779508  10.833259   9.540780  ...  9.136869  11.530145   8.263133   \n",
       "1   6.779508  10.833259   9.540780  ...  9.136869  11.530145   8.263133   \n",
       "2  16.631804  11.133786   7.663071  ...       NaN        NaN        NaN   \n",
       "3        NaN   4.873969  12.137977  ...       NaN        NaN        NaN   \n",
       "4   9.702233   6.167263   5.860414  ...  6.705081   9.684380  29.012508   \n",
       "\n",
       "         139       140       141        142        143  from_node     to_node  \n",
       "0  21.063414  6.517024  8.931566   9.542779   7.236827  628154368  1023689595  \n",
       "1  21.063414  6.517024  8.931566   9.542779   7.236827  628154368  1023689595  \n",
       "2        NaN       NaN       NaN        NaN        NaN  527147009    27537239  \n",
       "3  12.890066       NaN       NaN  13.178754        NaN  527147009    26908815  \n",
       "4  14.253002  8.932515  6.764400  10.154796  10.821180  628154370  3804638178  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our speed data uses segment ids, but the model uses sequential indexes, based on `.nodes()`\n",
    "import math\n",
    "id_to_idx = {}\n",
    "# defaultdict won't do what you expect in Pandas\n",
    "\n",
    "for id_ in df[\"from_node\"].unique():\n",
    "    id_to_idx[id_] = math.nan\n",
    "for id_ in df[\"to_node\"].unique():\n",
    "    id_to_idx[id_] = math.nan\n",
    "    \n",
    "for idx, id_ in enumerate(g_partition.nodes()):\n",
    "    id_to_idx[id_] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform ids to indeces\n",
    "df[\"from_node_idx\"] = df.replace({\"from_node\": id_to_idx})[\"from_node\"]\n",
    "df[\"to_node_idx\"] = df.replace({\"to_node\": id_to_idx})[\"to_node\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "      <th>from_node_idx</th>\n",
       "      <th>to_node_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.285511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>16.631804</td>\n",
       "      <td>11.133786</td>\n",
       "      <td>7.663071</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>27537239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.033088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873969</td>\n",
       "      <td>12.137977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.890066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.178754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>26908815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.952773</td>\n",
       "      <td>20.377332</td>\n",
       "      <td>9.472034</td>\n",
       "      <td>7.588203</td>\n",
       "      <td>9.702233</td>\n",
       "      <td>6.167263</td>\n",
       "      <td>5.860414</td>\n",
       "      <td>...</td>\n",
       "      <td>29.012508</td>\n",
       "      <td>14.253002</td>\n",
       "      <td>8.932515</td>\n",
       "      <td>6.764400</td>\n",
       "      <td>10.154796</td>\n",
       "      <td>10.821180</td>\n",
       "      <td>628154370</td>\n",
       "      <td>3804638178</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1197.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   0   1          2          3          4          5  \\\n",
       "0  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "1  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "2  result.average NaN NaN  18.285511        NaN        NaN  10.486210   \n",
       "3  result.average NaN NaN        NaN        NaN  19.033088        NaN   \n",
       "4  result.average NaN NaN  10.952773  20.377332   9.472034   7.588203   \n",
       "\n",
       "           6          7          8  ...        138        139       140  \\\n",
       "0   6.779508  10.833259   9.540780  ...   8.263133  21.063414  6.517024   \n",
       "1   6.779508  10.833259   9.540780  ...   8.263133  21.063414  6.517024   \n",
       "2  16.631804  11.133786   7.663071  ...        NaN        NaN       NaN   \n",
       "3        NaN   4.873969  12.137977  ...        NaN  12.890066       NaN   \n",
       "4   9.702233   6.167263   5.860414  ...  29.012508  14.253002  8.932515   \n",
       "\n",
       "        141        142        143  from_node     to_node  from_node_idx  \\\n",
       "0  8.931566   9.542779   7.236827  628154368  1023689595            0.0   \n",
       "1  8.931566   9.542779   7.236827  628154368  1023689595            0.0   \n",
       "2       NaN        NaN        NaN  527147009    27537239            1.0   \n",
       "3       NaN  13.178754        NaN  527147009    26908815            1.0   \n",
       "4  6.764400  10.154796  10.821180  628154370  3804638178            2.0   \n",
       "\n",
       "   to_node_idx  \n",
       "0        350.0  \n",
       "1        350.0  \n",
       "2       1608.0  \n",
       "3       2629.0  \n",
       "4       1197.0  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's build sparse 3D data tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def snapshot(t, df=df, g_partition=g_partition):\n",
    "    df_t = df[[t, \"from_node_idx\", \"to_node_idx\"]]\n",
    "    df_t = df_t.dropna()\n",
    "    row = df_t[\"from_node_idx\"].tolist()\n",
    "    col = df_t[\"to_node_idx\"].tolist()\n",
    "    data = df_t[t].tolist()\n",
    "    size = len(g_partition.nodes())  \n",
    "\n",
    "    return {\"indices\": (row, col), \"values\": data, \"shape\": (size, size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "def build_sparse_dataset(from_=0, to=TOTAL_T_STEPS):\n",
    "    dataset = {\"indices\": ([], [], []), \"values\": []}\n",
    "    for t in range(from_, to):\n",
    "\n",
    "        snap = snapshot(str(t))\n",
    "        dataset[\"indices\"][0].extend([t] * len(snap[\"indices\"][0]))\n",
    "        dataset[\"indices\"][1].extend(snap[\"indices\"][0])\n",
    "        dataset[\"indices\"][2].extend(snap[\"indices\"][1])\n",
    "        dataset[\"values\"].extend(snap[\"values\"])\n",
    "\n",
    "    i = torch.LongTensor(dataset[\"indices\"])\n",
    "    v = torch.FloatTensor(dataset[\"values\"])\n",
    "    return torch.sparse.FloatTensor(i, v, torch.Size((to, *snap[\"shape\"])))\n",
    "\n",
    "dataset = build_sparse_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's split sparse TxKxK Tensor into 3 TxKxK tensors for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nonzero_values_cnt = len(dataset._values())\n",
    "# what percent goes into training/validation/testing\n",
    "tng_pct = 0.7\n",
    "val_pct = 0.1\n",
    "tst_pct = 1 - tng_pct - val_pct\n",
    "# now we want to split list of all non-zeros promortionally:\n",
    "# [0, split1_idx], [split1_idx, split2_idx] and [split2_idx:]\n",
    "split1_idx = int(nonzero_values_cnt * tng_pct)\n",
    "split2_idx = -int(nonzero_values_cnt * tst_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# but we select indexes randomly\n",
    "idxs = list(range(nonzero_values_cnt))\n",
    "shuffle(idxs)\n",
    "# these are non-zero indexes\n",
    "tng_idxs = idxs[:split1_idx]\n",
    "val_idxs = idxs[split1_idx:split2_idx]\n",
    "tst_inxs = idxs[split2_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = {}\n",
    "for name, idxs in [('tng', tng_idxs), ('val', val_idxs), ('tst', tst_inxs)]:\n",
    "    i = torch.LongTensor([\n",
    "        dataset._indices()[0][idxs].tolist(),\n",
    "        dataset._indices()[1][idxs].tolist(),\n",
    "        dataset._indices()[2][idxs].tolist()\n",
    "    ])\n",
    "    v = torch.FloatTensor(dataset._values()[idxs])\n",
    "    \n",
    "    dataset_split[name] = torch.sparse.FloatTensor(i, v, dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tng': tensor(indices=tensor([[  19,  124,  122,  ...,   61,   56,    9],\n",
       "                        [3216, 1289, 1870,  ..., 2824, 2027, 1335],\n",
       "                        [ 448, 1628,  997,  ..., 2619, 2029, 3444]]),\n",
       "        values=tensor([  7.3950,  27.1839,   5.6074,  ...,   9.5655,\n",
       "                       185.3184,  11.4935]),\n",
       "        size=(144, 3475, 3475), nnz=131828, layout=torch.sparse_coo),\n",
       " 'val': tensor(indices=tensor([[  54,   50,  124,  ...,   63,   11,  102],\n",
       "                        [3293, 1507,  688,  ..., 1147,  634, 2911],\n",
       "                        [ 894, 2811, 2644,  ..., 3284, 1623, 1872]]),\n",
       "        values=tensor([12.6302, 12.2536,  2.7450,  ...,  5.0630,  4.6625,\n",
       "                        9.1221]),\n",
       "        size=(144, 3475, 3475), nnz=18834, layout=torch.sparse_coo),\n",
       " 'tst': tensor(indices=tensor([[ 100,   79,   69,  ...,   87,    6,   18],\n",
       "                        [1189, 2292, 1314,  ..., 3361, 1019, 1528],\n",
       "                        [2851, 2660, 1315,  ..., 2041,   17,  628]]),\n",
       "        values=tensor([ 5.3036, 11.5931,  4.0733,  ...,  3.9029,  5.5591,\n",
       "                       11.0894]),\n",
       "        size=(144, 3475, 3475), nnz=37665, layout=torch.sparse_coo)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.nmf.lsm_rn import LSM_RN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: False, used: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.datasets failed: Traceback (most recent call last):\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 300, in update_instances\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 300, in <genexpr>\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/torch/tensor.py\", line 390, in <lambda>\n",
      "    return iter(imap(lambda i: self[i], range(self.size(0))))\n",
      "RuntimeError: sparse tensors do not have strides\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot determine the DataLoader length of a IterableDataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ef80a91c4107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# most basic trainer, uses good defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m# return 1 when finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__run_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# init training constants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__layout_bookeeping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;31m# print model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__layout_bookeeping\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;31m# determine number of training batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_tng_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtng_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_tng_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_tng_batches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_percent_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_sampler\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# with iterable-style dataset, this will error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# `len(dataloader)`, `list(dataloader)` will fail.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# see NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot determine the DataLoader length of a IterableDataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot determine the DataLoader length of a IterableDataset"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "model = LSM_RN(TOTAL_T_STEPS, n=3475, k=50, λ=0.5, adj_mat=A, datasets=dataset_split)\n",
    "# most basic trainer, uses good defaults\n",
    "trainer = Trainer()    \n",
    "trainer.fit(model)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.2.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
