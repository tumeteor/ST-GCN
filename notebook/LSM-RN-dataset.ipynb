{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_T_STEPS = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get adjacency matrix for our partitions of Jurbey map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graph_utils import partition_graph_by_lonlat\n",
    "import networkx as nx\n",
    "from jurbey.jurbey import JURBEY\n",
    "\n",
    "with open(\"../data/1556798416403.jurbey\", 'rb') as tempf:\n",
    "    g = JURBEY.load(tempf.read())\n",
    "    \n",
    "g_partition = partition_graph_by_lonlat(g)\n",
    "\n",
    "A = nx.adjacency_matrix(g_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert timeseries raw data into sparse tensor\n",
    "Tensor size: 144 timestamps by adjacency matrix of speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"../data/timeseries_speed_april_first_week.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>9.136869</td>\n",
       "      <td>11.530145</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>9.136869</td>\n",
       "      <td>11.530145</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.285511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>16.631804</td>\n",
       "      <td>11.133786</td>\n",
       "      <td>7.663071</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>27537239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.033088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873969</td>\n",
       "      <td>12.137977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.890066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.178754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>26908815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.952773</td>\n",
       "      <td>20.377332</td>\n",
       "      <td>9.472034</td>\n",
       "      <td>7.588203</td>\n",
       "      <td>9.702233</td>\n",
       "      <td>6.167263</td>\n",
       "      <td>5.860414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.705081</td>\n",
       "      <td>9.684380</td>\n",
       "      <td>29.012508</td>\n",
       "      <td>14.253002</td>\n",
       "      <td>8.932515</td>\n",
       "      <td>6.764400</td>\n",
       "      <td>10.154796</td>\n",
       "      <td>10.821180</td>\n",
       "      <td>628154370</td>\n",
       "      <td>3804638178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   0   1          2          3          4          5  \\\n",
       "0  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "1  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "2  result.average NaN NaN  18.285511        NaN        NaN  10.486210   \n",
       "3  result.average NaN NaN        NaN        NaN  19.033088        NaN   \n",
       "4  result.average NaN NaN  10.952773  20.377332   9.472034   7.588203   \n",
       "\n",
       "           6          7          8  ...       136        137        138  \\\n",
       "0   6.779508  10.833259   9.540780  ...  9.136869  11.530145   8.263133   \n",
       "1   6.779508  10.833259   9.540780  ...  9.136869  11.530145   8.263133   \n",
       "2  16.631804  11.133786   7.663071  ...       NaN        NaN        NaN   \n",
       "3        NaN   4.873969  12.137977  ...       NaN        NaN        NaN   \n",
       "4   9.702233   6.167263   5.860414  ...  6.705081   9.684380  29.012508   \n",
       "\n",
       "         139       140       141        142        143  from_node     to_node  \n",
       "0  21.063414  6.517024  8.931566   9.542779   7.236827  628154368  1023689595  \n",
       "1  21.063414  6.517024  8.931566   9.542779   7.236827  628154368  1023689595  \n",
       "2        NaN       NaN       NaN        NaN        NaN  527147009    27537239  \n",
       "3  12.890066       NaN       NaN  13.178754        NaN  527147009    26908815  \n",
       "4  14.253002  8.932515  6.764400  10.154796  10.821180  628154370  3804638178  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our speed data uses segment ids, but the model uses sequential indexes, based on `.nodes()`\n",
    "import math\n",
    "id_to_idx = {}\n",
    "# defaultdict won't do what you expect in Pandas\n",
    "\n",
    "for id_ in df[\"from_node\"].unique():\n",
    "    id_to_idx[id_] = math.nan\n",
    "for id_ in df[\"to_node\"].unique():\n",
    "    id_to_idx[id_] = math.nan\n",
    "    \n",
    "for idx, id_ in enumerate(g_partition.nodes()):\n",
    "    id_to_idx[id_] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform ids to indeces\n",
    "df[\"from_node_idx\"] = df.replace({\"from_node\": id_to_idx})[\"from_node\"]\n",
    "df[\"to_node_idx\"] = df.replace({\"to_node\": id_to_idx})[\"to_node\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "      <th>from_node_idx</th>\n",
       "      <th>to_node_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.817616</td>\n",
       "      <td>29.111668</td>\n",
       "      <td>8.288389</td>\n",
       "      <td>6.779508</td>\n",
       "      <td>10.833259</td>\n",
       "      <td>9.540780</td>\n",
       "      <td>...</td>\n",
       "      <td>8.263133</td>\n",
       "      <td>21.063414</td>\n",
       "      <td>6.517024</td>\n",
       "      <td>8.931566</td>\n",
       "      <td>9.542779</td>\n",
       "      <td>7.236827</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.285511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>16.631804</td>\n",
       "      <td>11.133786</td>\n",
       "      <td>7.663071</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>27537239</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1608.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.033088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.873969</td>\n",
       "      <td>12.137977</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.890066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.178754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>26908815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.952773</td>\n",
       "      <td>20.377332</td>\n",
       "      <td>9.472034</td>\n",
       "      <td>7.588203</td>\n",
       "      <td>9.702233</td>\n",
       "      <td>6.167263</td>\n",
       "      <td>5.860414</td>\n",
       "      <td>...</td>\n",
       "      <td>29.012508</td>\n",
       "      <td>14.253002</td>\n",
       "      <td>8.932515</td>\n",
       "      <td>6.764400</td>\n",
       "      <td>10.154796</td>\n",
       "      <td>10.821180</td>\n",
       "      <td>628154370</td>\n",
       "      <td>3804638178</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1197.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   0   1          2          3          4          5  \\\n",
       "0  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "1  result.average NaN NaN        NaN  28.817616  29.111668   8.288389   \n",
       "2  result.average NaN NaN  18.285511        NaN        NaN  10.486210   \n",
       "3  result.average NaN NaN        NaN        NaN  19.033088        NaN   \n",
       "4  result.average NaN NaN  10.952773  20.377332   9.472034   7.588203   \n",
       "\n",
       "           6          7          8  ...        138        139       140  \\\n",
       "0   6.779508  10.833259   9.540780  ...   8.263133  21.063414  6.517024   \n",
       "1   6.779508  10.833259   9.540780  ...   8.263133  21.063414  6.517024   \n",
       "2  16.631804  11.133786   7.663071  ...        NaN        NaN       NaN   \n",
       "3        NaN   4.873969  12.137977  ...        NaN  12.890066       NaN   \n",
       "4   9.702233   6.167263   5.860414  ...  29.012508  14.253002  8.932515   \n",
       "\n",
       "        141        142        143  from_node     to_node  from_node_idx  \\\n",
       "0  8.931566   9.542779   7.236827  628154368  1023689595            0.0   \n",
       "1  8.931566   9.542779   7.236827  628154368  1023689595            0.0   \n",
       "2       NaN        NaN        NaN  527147009    27537239            1.0   \n",
       "3       NaN  13.178754        NaN  527147009    26908815            1.0   \n",
       "4  6.764400  10.154796  10.821180  628154370  3804638178            2.0   \n",
       "\n",
       "   to_node_idx  \n",
       "0        350.0  \n",
       "1        350.0  \n",
       "2       1608.0  \n",
       "3       2629.0  \n",
       "4       1197.0  \n",
       "\n",
       "[5 rows x 149 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's build sparse 3D data tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def snapshot(t, df=df, g_partition=g_partition):\n",
    "    df_t = df[[t, \"from_node_idx\", \"to_node_idx\"]]\n",
    "    df_t = df_t.dropna()\n",
    "    row = df_t[\"from_node_idx\"].tolist()\n",
    "    col = df_t[\"to_node_idx\"].tolist()\n",
    "    data = df_t[t].tolist()\n",
    "    size = len(g_partition.nodes())  \n",
    "\n",
    "    return {\"indices\": (row, col), \"values\": data, \"shape\": (size, size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "def build_sparse_dataset(from_=0, to=TOTAL_T_STEPS):\n",
    "    dataset = {\"indices\": ([], [], []), \"values\": []}\n",
    "    for t in range(from_, to):\n",
    "\n",
    "        snap = snapshot(str(t))\n",
    "        dataset[\"indices\"][0].extend([t] * len(snap[\"indices\"][0]))\n",
    "        dataset[\"indices\"][1].extend(snap[\"indices\"][0])\n",
    "        dataset[\"indices\"][2].extend(snap[\"indices\"][1])\n",
    "        dataset[\"values\"].extend(snap[\"values\"])\n",
    "\n",
    "    i = torch.LongTensor(dataset[\"indices\"])\n",
    "    v = torch.FloatTensor(dataset[\"values\"])\n",
    "    return torch.sparse.FloatTensor(i, v, torch.Size((to, *snap[\"shape\"])))\n",
    "\n",
    "dataset = build_sparse_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's split sparse TxKxK Tensor into 3 TxKxK tensors for training, validation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "nonzero_values_cnt = len(dataset._values())\n",
    "# what percent goes into training/validation/testing\n",
    "tng_pct = 0.7\n",
    "val_pct = 0.1\n",
    "tst_pct = 1 - tng_pct - val_pct\n",
    "# now we want to split list of all non-zeros promortionally:\n",
    "# [0, split1_idx], [split1_idx, split2_idx] and [split2_idx:]\n",
    "split1_idx = int(nonzero_values_cnt * tng_pct)\n",
    "split2_idx = -int(nonzero_values_cnt * tst_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "# but we select indexes randomly\n",
    "idxs = list(range(nonzero_values_cnt))\n",
    "shuffle(idxs)\n",
    "# these are non-zero indexes\n",
    "tng_idxs = idxs[:split1_idx]\n",
    "val_idxs = idxs[split1_idx:split2_idx]\n",
    "tst_inxs = idxs[split2_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split = {}\n",
    "for name, idxs in [('tng', tng_idxs), ('val', val_idxs), ('tst', tst_inxs)]:\n",
    "    i = torch.LongTensor([\n",
    "        dataset._indices()[0][idxs].tolist(),\n",
    "        dataset._indices()[1][idxs].tolist(),\n",
    "        dataset._indices()[2][idxs].tolist()\n",
    "    ])\n",
    "    v = torch.FloatTensor(dataset._values()[idxs])\n",
    "    # NOTE sparse tensor is not supported yet by the model\n",
    "    dataset_split[name] = torch.sparse.FloatTensor(i, v, dataset.shape).to_dense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.nmf.lsm_rn failed: Traceback (most recent call last):\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 450, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 387, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 357, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 317, in update_instances\n",
      "    update_instances(old, new, obj, visited)\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 300, in update_instances\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 300, in <genexpr>\n",
      "    for obj in (obj for obj in objects if id(obj) not in visited):\n",
      "  File \"/Users/dscsade/.local/share/virtualenvs/speed-imputation-gDyT7lob/lib/python3.6/site-packages/torch/tensor.py\", line 390, in <lambda>\n",
      "    return iter(imap(lambda i: self[i], range(self.size(0))))\n",
      "RuntimeError: sparse tensors do not have strides\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: False, used: False\n",
      "Empty DataFrame\n",
      "Columns: [Name, Type, Params]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [02:19<00:03,  3.76s/it, avg_laplacian_term=102, avg_val_fro=234, avg_val_loss=336, avg_val_mae=9.64, batch_nb=16, epoch=0, tng_loss=739.647, v_nb=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save callback...\n",
      "\n",
      "Epoch 00001: avg_val_mae improved from inf to 9.64308, saving model to lsm_rn.ckpt/_ckpt_epoch_1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [02:15<00:03,  3.86s/it, avg_laplacian_term=100, avg_val_fro=234, avg_val_loss=334, avg_val_mae=9.6, batch_nb=16, epoch=1, tng_loss=751.846, v_nb=0] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save callback...\n",
      "\n",
      "Epoch 00002: avg_val_mae improved from 9.64308 to 9.59567, saving model to lsm_rn.ckpt/_ckpt_epoch_2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [02:15<00:03,  3.71s/it, avg_laplacian_term=99.1, avg_val_fro=234, avg_val_loss=333, avg_val_mae=9.53, batch_nb=16, epoch=2, tng_loss=754.271, v_nb=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save callback...\n",
      "\n",
      "Epoch 00003: avg_val_mae improved from 9.59567 to 9.52733, saving model to lsm_rn.ckpt/_ckpt_epoch_3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [02:13<00:03,  3.76s/it, avg_laplacian_term=97.7, avg_val_fro=233, avg_val_loss=331, avg_val_mae=9.44, batch_nb=16, epoch=3, tng_loss=752.452, v_nb=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save callback...\n",
      "\n",
      "Epoch 00004: avg_val_mae improved from 9.52733 to 9.44399, saving model to lsm_rn.ckpt/_ckpt_epoch_4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [01:22<01:01,  4.11s/it, avg_laplacian_term=97.7, avg_val_fro=233, avg_val_loss=331, avg_val_mae=9.44, batch_nb=16, epoch=4, tng_loss=747.000, v_nb=0]"
     ]
    }
   ],
   "source": [
    "from src.nmf.lsm_rn import LSM_RN\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from test_tube import Experiment\n",
    "\n",
    "\n",
    "model = LSM_RN(TOTAL_T_STEPS, n=3475, k=50, Î»=0.1, adj_mat=A, datasets=dataset_split, batch_size=8)\n",
    "exp = Experiment(save_dir='lsm_rn_logs')\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='lsm_rn.ckpt',\n",
    "    save_best_only=True,\n",
    "    verbose=True,\n",
    "    monitor='avg_val_mae',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "\n",
    "# most basic trainer, uses good defaults\n",
    "trainer = Trainer(experiment=exp, checkpoint_callback=checkpoint_callback)    \n",
    "trainer.fit(model)\n",
    "#TODO lr decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.2.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
