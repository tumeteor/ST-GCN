{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.graph_utils import partition_graph_by_lonlat\n",
    "import networkx as nx\n",
    "from jurbey.jurbey import JURBEY\n",
    "\n",
    "with open(\"../data/berlin.jurbey\", 'rb') as tempf:\n",
    "    g = JURBEY.load(tempf.read())\n",
    "print(g.number_of_nodes())\n",
    "g_partition = partition_graph_by_lonlat(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to edge-based graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "L = nx.line_graph(nx.DiGraph(g_partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arc(arcType=<ArcType.LANE_STRAIGHT: 'LANE_STRAIGHT'>, roadClass=<RoadClass.MajorRoad: 2>, roadAccessibility=<RoadAccessibility.NoRestriction: 1>, metadata={'bicycle': 'no', 'highway': 'primary', 'lanes': '4', 'lit': 'yes', 'maxspeed': '50', 'name': 'Bismarckstraße', 'oneway': 'yes', 'postal_code': '10625', 'ref': 'B 2;B 5', 'surface': 'asphalt', 'turn:lanes': 'through|through|through;right|right'}, signs=[], vehicleAccessibility=[], geometry=[GeoCoordinates(lon=13.3207077, lat=52.5123944, alt=nan), GeoCoordinates(lon=13.3207877, lat=52.5123711, alt=nan)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(L.nodes())\n",
    "g_partition[nodes[10][0]][nodes[10][1]]['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract dynamic (speed) + static features from nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = StandardScaler()\n",
    "def arc_features(arc):\n",
    "    arc = g_partition[arc[0]][arc[1]]\n",
    "    return [ \n",
    "        float(arc['data'].metadata.get('maxspeed', '50')), \n",
    "        arc['data'].metadata.get('lanes', '1'),\n",
    "        arc['data'].metadata['highway'],\n",
    "        arc['data'].roadClass.name\n",
    "    ]\n",
    "def construct_features():\n",
    "    data = list()\n",
    "    for node in L.nodes:\n",
    "        data.append(arc_features(node))\n",
    "    return enc.fit_transform(data)\n",
    "    \n",
    "X = construct_features()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5.0, 10.0, 20.0, 30.0, 50.0], dtype=object),\n",
       " array(['1', '2', '3', '4', '5'], dtype=object),\n",
       " array(['access_ramp', 'corridor', 'living_street', 'platform', 'primary',\n",
       "        'residential', 'secondary', 'secondary_link', 'service',\n",
       "        'tertiary', 'tertiary_link', 'unclassified'], dtype=object),\n",
       " array(['DirtRoad', 'LocalRoad', 'MajorRoad'], dtype=object)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6163, 25)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess adjacency matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = nx.to_scipy_sparse_matrix(L, format=\"coo\")\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "                                    \n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "# build symmetric adjacency matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "                                    \n",
    "adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "                                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6163, 6163])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "#Our speed data uses segment ids, but the model uses sequential indexes, based on `.nodes()`\n",
    "import math\n",
    "id_to_idx = {}\n",
    "# defaultdict won't do what you expect in Pandas\n",
    "df = pandas.read_csv(\"../data/timeseries_speed_april_first_week.csv\")\n",
    "\n",
    "df = df.T\n",
    "l = (df.isnull().mean() < 0.5).tolist()\n",
    "\n",
    "indices = [i for i, x in enumerate(l) if x == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0   1   2          3          4          5          6          7  \\\n",
      "0        NaN NaN NaN  10.854457        NaN   5.680978   7.036838   1.499997   \n",
      "1        NaN NaN NaN  10.854457        NaN   5.680978   7.036838   1.499997   \n",
      "2        NaN NaN NaN        NaN        NaN  10.486210        NaN        NaN   \n",
      "3        NaN NaN NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "4        NaN NaN NaN  10.468811  10.636621  10.288534  10.617513   1.758539   \n",
      "5        NaN NaN NaN        NaN        NaN        NaN  10.286999        NaN   \n",
      "6        NaN NaN NaN  10.854457        NaN   5.680978   7.036838   1.499997   \n",
      "7  10.278846 NaN NaN        NaN  10.831409        NaN   3.140737   2.073876   \n",
      "8        NaN NaN NaN        NaN        NaN  10.298252   1.220956  10.298252   \n",
      "9        NaN NaN NaN        NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "           8          9  ...  134        135        136        137        138  \\\n",
      "0  10.088634  10.587459  ...  NaN   0.038248  10.581123        NaN        NaN   \n",
      "1  10.088634  10.587459  ...  NaN   0.038248  10.581123        NaN        NaN   \n",
      "2  10.937218        NaN  ...  NaN        NaN        NaN        NaN        NaN   \n",
      "3        NaN        NaN  ...  NaN        NaN        NaN        NaN        NaN   \n",
      "4   3.404401  10.224568  ...  NaN        NaN   6.098767  10.257657  10.586166   \n",
      "5        NaN  10.833570  ...  NaN  10.395120  10.537584  10.286999        NaN   \n",
      "6   5.044317  10.587459  ...  NaN   0.038248   0.961866        NaN        NaN   \n",
      "7   0.385263   4.104480  ...  NaN  10.395120  10.505827  10.517314        NaN   \n",
      "8        NaN        NaN  ...  NaN        NaN        NaN        NaN        NaN   \n",
      "9        NaN        NaN  ...  NaN        NaN        NaN        NaN        NaN   \n",
      "\n",
      "   139        140        141        142        143  \n",
      "0  NaN        NaN        NaN  10.850843  10.036408  \n",
      "1  NaN        NaN        NaN  10.850843  10.036408  \n",
      "2  NaN        NaN        NaN        NaN        NaN  \n",
      "3  NaN        NaN        NaN        NaN        NaN  \n",
      "4  NaN  10.669476   4.313417  10.392901  10.518310  \n",
      "5  NaN        NaN   7.238553  10.497979  10.491733  \n",
      "6  NaN        NaN        NaN  10.850843  10.036408  \n",
      "7  NaN        NaN  10.189923  10.436750   4.196431  \n",
      "8  NaN        NaN        NaN        NaN        NaN  \n",
      "9  NaN        NaN        NaN        NaN        NaN  \n",
      "\n",
      "[10 rows x 144 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>10.088634</td>\n",
       "      <td>10.587459</td>\n",
       "      <td>...</td>\n",
       "      <td>10.581123</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>10.088634</td>\n",
       "      <td>10.587459</td>\n",
       "      <td>...</td>\n",
       "      <td>10.581123</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>10.937218</td>\n",
       "      <td>10.587459</td>\n",
       "      <td>...</td>\n",
       "      <td>10.581123</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>527147009</td>\n",
       "      <td>27537239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>10.617513</td>\n",
       "      <td>1.758539</td>\n",
       "      <td>10.937218</td>\n",
       "      <td>10.224568</td>\n",
       "      <td>...</td>\n",
       "      <td>6.098767</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.518310</td>\n",
       "      <td>527147009</td>\n",
       "      <td>26908815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.636621</td>\n",
       "      <td>10.288534</td>\n",
       "      <td>10.617513</td>\n",
       "      <td>1.758539</td>\n",
       "      <td>3.404401</td>\n",
       "      <td>10.224568</td>\n",
       "      <td>...</td>\n",
       "      <td>6.098767</td>\n",
       "      <td>10.257657</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>4.313417</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.518310</td>\n",
       "      <td>628154370</td>\n",
       "      <td>3804638178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.636621</td>\n",
       "      <td>10.288534</td>\n",
       "      <td>10.286999</td>\n",
       "      <td>1.758539</td>\n",
       "      <td>3.404401</td>\n",
       "      <td>10.833570</td>\n",
       "      <td>...</td>\n",
       "      <td>10.537584</td>\n",
       "      <td>10.286999</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>7.238553</td>\n",
       "      <td>10.497979</td>\n",
       "      <td>10.491733</td>\n",
       "      <td>628154372</td>\n",
       "      <td>26938222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>5.044317</td>\n",
       "      <td>10.587459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961866</td>\n",
       "      <td>10.286999</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>7.238553</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154375</td>\n",
       "      <td>1560866145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.278846</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>3.140737</td>\n",
       "      <td>2.073876</td>\n",
       "      <td>0.385263</td>\n",
       "      <td>4.104480</td>\n",
       "      <td>...</td>\n",
       "      <td>10.505827</td>\n",
       "      <td>10.517314</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.189923</td>\n",
       "      <td>10.436750</td>\n",
       "      <td>4.196431</td>\n",
       "      <td>5791596551</td>\n",
       "      <td>1321327852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.278846</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>10.298252</td>\n",
       "      <td>1.220956</td>\n",
       "      <td>10.298252</td>\n",
       "      <td>0.385263</td>\n",
       "      <td>4.104480</td>\n",
       "      <td>...</td>\n",
       "      <td>10.505827</td>\n",
       "      <td>10.517314</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.189923</td>\n",
       "      <td>10.436750</td>\n",
       "      <td>4.196431</td>\n",
       "      <td>5791621141</td>\n",
       "      <td>4782446443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.278846</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>10.298252</td>\n",
       "      <td>1.220956</td>\n",
       "      <td>10.298252</td>\n",
       "      <td>0.385263</td>\n",
       "      <td>4.104480</td>\n",
       "      <td>...</td>\n",
       "      <td>10.505827</td>\n",
       "      <td>10.517314</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>10.189923</td>\n",
       "      <td>10.436750</td>\n",
       "      <td>4.196431</td>\n",
       "      <td>5791621141</td>\n",
       "      <td>26875019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1          2          3          4          5  \\\n",
       "0  10.854457  10.854457  10.854457  10.854457   5.680978   5.680978   \n",
       "1  10.854457  10.854457  10.854457  10.854457   5.680978   5.680978   \n",
       "2  10.854457  10.854457  10.854457  10.854457  10.486210  10.486210   \n",
       "3  10.468811  10.468811  10.468811  10.468811  10.486210  10.486210   \n",
       "4  10.468811  10.468811  10.468811  10.468811  10.636621  10.288534   \n",
       "5  10.468811  10.468811  10.468811  10.468811  10.636621  10.288534   \n",
       "6  10.854457  10.854457  10.854457  10.854457  10.831409   5.680978   \n",
       "7  10.278846  10.854457  10.854457  10.854457  10.831409   5.680978   \n",
       "8  10.278846  10.854457  10.854457  10.854457  10.831409  10.298252   \n",
       "9  10.278846  10.854457  10.854457  10.854457  10.831409  10.298252   \n",
       "\n",
       "           6          7          8          9  ...        136        137  \\\n",
       "0   7.036838   1.499997  10.088634  10.587459  ...  10.581123  10.850843   \n",
       "1   7.036838   1.499997  10.088634  10.587459  ...  10.581123  10.850843   \n",
       "2   7.036838   1.499997  10.937218  10.587459  ...  10.581123  10.850843   \n",
       "3  10.617513   1.758539  10.937218  10.224568  ...   6.098767  10.392901   \n",
       "4  10.617513   1.758539   3.404401  10.224568  ...   6.098767  10.257657   \n",
       "5  10.286999   1.758539   3.404401  10.833570  ...  10.537584  10.286999   \n",
       "6   7.036838   1.499997   5.044317  10.587459  ...   0.961866  10.286999   \n",
       "7   3.140737   2.073876   0.385263   4.104480  ...  10.505827  10.517314   \n",
       "8   1.220956  10.298252   0.385263   4.104480  ...  10.505827  10.517314   \n",
       "9   1.220956  10.298252   0.385263   4.104480  ...  10.505827  10.517314   \n",
       "\n",
       "         138        139        140        141        142        143  \\\n",
       "0  10.850843  10.850843  10.850843  10.850843  10.850843  10.036408   \n",
       "1  10.850843  10.850843  10.850843  10.850843  10.850843  10.036408   \n",
       "2  10.850843  10.850843  10.850843  10.850843  10.850843  10.036408   \n",
       "3  10.392901  10.392901  10.392901  10.392901  10.392901  10.518310   \n",
       "4  10.586166  10.669476  10.669476   4.313417  10.392901  10.518310   \n",
       "5  10.586166  10.669476  10.669476   7.238553  10.497979  10.491733   \n",
       "6  10.586166  10.669476  10.669476   7.238553  10.850843  10.036408   \n",
       "7  10.586166  10.669476  10.669476  10.189923  10.436750   4.196431   \n",
       "8  10.586166  10.669476  10.669476  10.189923  10.436750   4.196431   \n",
       "9  10.586166  10.669476  10.669476  10.189923  10.436750   4.196431   \n",
       "\n",
       "    from_node     to_node  \n",
       "0   628154368  1023689595  \n",
       "1   628154368  1023689595  \n",
       "2   527147009    27537239  \n",
       "3   527147009    26908815  \n",
       "4   628154370  3804638178  \n",
       "5   628154372    26938222  \n",
       "6   628154375  1560866145  \n",
       "7  5791596551  1321327852  \n",
       "8  5791621141  4782446443  \n",
       "9  5791621141    26875019  \n",
       "\n",
       "[10 rows x 146 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_idx = {}\n",
    "\n",
    "for idx, id_ in enumerate(L.nodes()):\n",
    "    id_to_idx[id_] = idx\n",
    "\n",
    "df1 = df['Unnamed: 0']\n",
    "df2 = df['from_node']\n",
    "df3 = df['to_node']\n",
    "\n",
    "df = df.loc[:, df.columns != 'Unnamed: 0']\n",
    "df = df.loc[:, df.columns != 'from_node']\n",
    "df = df.loc[:, df.columns != 'to_node']\n",
    "print(df[0:10])\n",
    "\n",
    "df = df.T\n",
    "for column in df:\n",
    "    df[column] = pandas.to_numeric(df[column])\n",
    "\n",
    "df = df.interpolate(method='nearest', axis=1)\n",
    "\n",
    "df = df.fillna(method='backfill')\n",
    "df = df.T\n",
    "df['from_node'] = df2\n",
    "df['to_node'] = df3\n",
    "df[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create rolling window tensor dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.sparse\n",
    "TOTAL_T_STEPS = 144\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "def build_dataset_to_sparse_tensor(from_=0, to=TOTAL_T_STEPS):\n",
    "    dataset = list()\n",
    "    for t in range(from_, to):\n",
    "        features_at_t = [[50, '4', 'primary', 'MajorRoad']] * len(L.nodes)\n",
    "        for _, row in df.iterrows():\n",
    "            arc = (row['from_node'], row['to_node'])\n",
    "            features_at_t[id_to_idx[arc]] = arc_features(arc, speed=row[str(t)])        \n",
    "        dataset.append(sparse_mx_to_torch_sparse_tensor(enc.fit_transform(features_at_t)))\n",
    "    return torch.stack(dataset, dim=0)\n",
    "    \n",
    "def build_dataset_to_numpy_tensor(from_=0, to=TOTAL_T_STEPS):\n",
    "    dataset = list()\n",
    "    for t in range(from_, to):\n",
    "        cat_features_at_t = [[50, '4', 'primary', 'MajorRoad']] * len(L.nodes)\n",
    "        speed_features_at_t = [50] * len(L.nodes) \n",
    "        for _, row in df.iterrows():\n",
    "\n",
    "            arc = (row['from_node'], row['to_node'])\n",
    "            cat_features_at_t[id_to_idx[arc]] = arc_features(arc)\n",
    "            speed_features_at_t[id_to_idx[arc]] = row[str(t)]\n",
    "        dataset.append(np.concatenate([scaler.fit_transform(np.array(speed_features_at_t).reshape(-1, 1)), enc.fit_transform(cat_features_at_t).toarray()], axis=1))\n",
    "    return np.stack(dataset, axis=0)\n",
    "\n",
    "Y = build_dataset_to_numpy_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 6163, 26)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cannot get indices on an uncoalesced tensor, please call .coalesce() first",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-404bfc99540a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# serialize the tensor dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../data/dataset_st_indices.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../data/dataset_st_values.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../data/dataset_st_size.pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot get indices on an uncoalesced tensor, please call .coalesce() first"
     ]
    }
   ],
   "source": [
    "# serialize the sparse tensor dataset\n",
    "torch.save(X.indices(), \"../data/dataset_st_indices.pt\", pickle_protocol=4)\n",
    "torch.save(X.values(), \"../data/dataset_st_values.pt\", pickle_protocol=4)\n",
    "torch.save(X.size(), \"../data/dataset_st_size.pt\", pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6163, 26, 144)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.moveaxis(Y, source=(0,1,2), destination=(2,0,1))\n",
    "# num_vertices, num_features, num_timesteps\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13718426  0.5436345   0.5950063   0.70373938  0.73311878 -1.10124471\n",
      " -0.94188473  0.15991669 -1.16780836 -0.93367117 -0.23873298  1.08977847\n",
      " -1.04627901 -0.72165827 -0.72327439 -1.09240688  0.37351051  0.73152804\n",
      " -1.1700183   0.78203765  0.66986469  0.45078987  0.81317076  0.54371195\n",
      "  0.78306068 -1.21507196 -1.01551294 -1.90808661  0.73996502  0.95473612\n",
      "  0.97511705 -0.21307026 -1.3895476  -1.43349213  0.79868202  0.746489\n",
      "  0.80919106  1.21579334 -1.0314559  -1.12936242 -0.02139245  0.32627472\n",
      " -1.24840088  0.73200666  0.62594342  0.74334193  0.51163755 -1.72947328\n",
      "  0.64648075  0.16376414  0.48281781  0.8951816   0.83741862 -1.04912798\n",
      " -1.25316306  0.80470628 -1.5152136   0.64410151 -1.2459627   0.87350888\n",
      "  1.03067684 -1.07928412  0.08454025  1.04592802 -1.03485577  0.6643083\n",
      "  0.65086031  0.64458177 -2.0198933   0.69249936 -1.29862115  0.44240427\n",
      " -0.08637656 -0.12929537 -0.21432033  0.02342123 -1.10381474 -1.22963185\n",
      "  0.13253811  0.90564012  0.65383961 -1.25599206 -1.53865669 -1.31275614\n",
      " -0.67200446 -0.92961067 -0.90073358  1.1519846  -1.09789714  0.9101379\n",
      " -1.18797187  0.58282704  0.73143065  0.73686347  0.53595719  0.63744502\n",
      "  0.51568466  0.55007677  0.53820691 -1.36997682 -1.25867756 -1.29051525\n",
      " -1.31326862 -1.12459976  0.67034116  0.71350071 -1.0128305  -1.20338349\n",
      " -1.0537353  -1.06942993  0.92387674  0.78636565  0.80802677  0.91263588\n",
      "  0.83136846  0.51546564  0.5618813   0.66430642  0.59477041  0.59658293\n",
      "  0.60744621 -1.89537445  0.65181828  0.60547028  0.49592257  0.7047073\n",
      "  0.64493806  0.57526768 -1.57093025 -1.48213334 -1.53638705  0.76360092\n",
      "  0.89057407  0.87210251  0.73559255  0.76850116  0.67582908  0.61868423\n",
      " -1.3099535   0.73964268  0.63268222  0.77897079  0.67614376  0.55982662]\n"
     ]
    }
   ],
   "source": [
    "print(X[120,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(X, num_timesteps_input, num_timesteps_output):\n",
    "    \"\"\"\n",
    "    Takes node features for the graph and divides them into multiple samples\n",
    "    along the time-axis by sliding a window of size (num_timesteps_input+\n",
    "    num_timesteps_output) across it in steps of 1.\n",
    "    :param X: Node features of shape (num_vertices, num_features,\n",
    "    num_timesteps)\n",
    "    :return:\n",
    "        - Node features divided into multiple samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_input).\n",
    "        - Node targets for the samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_output).\n",
    "    \"\"\"\n",
    "    # Generate the beginning index and the ending index of a sample, which\n",
    "    # contains (num_points_for_training + num_points_for_predicting) points\n",
    "    indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n",
    "               in range(X.shape[2] - (\n",
    "                num_timesteps_input + num_timesteps_output) + 1)]\n",
    "\n",
    "    # Save samples\n",
    "    features, target = [], []\n",
    "    for i, j in indices:\n",
    "        features.append(\n",
    "            X[:, :, i: i + num_timesteps_input])\n",
    "        target.append(X[:, :, i + num_timesteps_input: j])\n",
    "\n",
    "    return torch.from_numpy(np.array(features)).permute(0,1,3,2), \\\n",
    "           torch.from_numpy(np.array(target)).permute(0,1,3,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_dataset_concat(X, num_timesteps_input, num_timesteps_output):\n",
    "    \"\"\"\n",
    "    Takes node features for the graph and divides them into multiple samples\n",
    "    along the time-axis by sliding a window of size (num_timesteps_input+\n",
    "    num_timesteps_output) across it in steps of 1.\n",
    "    :param X: Node features of shape (num_vertices, num_features,\n",
    "    num_timesteps)\n",
    "    :return:\n",
    "        - Node data (features + labels) divided into multiple samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_input).\n",
    "        \n",
    "    \"\"\"\n",
    "    # Generate the beginning index and the ending index of a sample, which\n",
    "    # contains (num_points_for_training + num_points_for_predicting) points\n",
    "    indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n",
    "               in range(X.shape[2] - (\n",
    "                num_timesteps_input + num_timesteps_output) + 1)]\n",
    "\n",
    "    # Save samples\n",
    "    dataset = []\n",
    "    for i, j in indices:\n",
    "        dataset.append(X[:, :, i: j])\n",
    "\n",
    "    return torch.from_numpy(np.array(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training: torch.Size([89, 6163, 26, 12]), 3\n",
      "shape of validation: torch.Size([18, 6163, 26, 12]), 1\n",
      "shape of testing: torch.Size([4, 6163, 26, 12]), 209\n"
     ]
    }
   ],
   "source": [
    "# training, validation, testing : 0.7, 0.1, 0.2\n",
    "split_line1 = int(X.shape[2] * 0.7)\n",
    "split_line2 = int(X.shape[2] * 0.9)\n",
    "train_original_data = X[:, :, :split_line1]\n",
    "val_original_data = X[:, :, split_line1:split_line2]\n",
    "test_original_data = X[:, :, split_line2:]\n",
    "\n",
    "\n",
    "look_back = 9\n",
    "look_ahead = 3\n",
    "# num_samples, num_nodes, num_timesteps, num_features\n",
    "\n",
    "training_data = generate_dataset_concat(train_original_data,\n",
    "                                                       num_timesteps_input=look_back,\n",
    "                                                       num_timesteps_output=look_ahead)\n",
    "valid_data = generate_dataset_concat(val_original_data,\n",
    "                                             num_timesteps_input=look_back,\n",
    "                                             num_timesteps_output=look_ahead)\n",
    "test_data = generate_dataset_concat(test_original_data,\n",
    "                                               num_timesteps_input=look_back,\n",
    "                                               num_timesteps_output=look_ahead)\n",
    "\n",
    "print(f\"shape of training: {training_data.shape}\")\n",
    "print(f\"shape of validation: {valid_data.shape}\")\n",
    "print(f\"shape of testing: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['train'] = (training_data)\n",
    "data['valid'] = (valid_data)\n",
    "data['test'] = (test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now start training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: False, used: False\n"
     ]
    }
   ],
   "source": [
    "from test_tube import Experiment \n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "\n",
    "# PyTorch summarywriter with a few bells and whistles    \n",
    "exp = Experiment(save_dir=os.getcwd())\n",
    "\n",
    "# pass in experiment for automatic tensorboard logging.    \n",
    "trainer = Trainer(experiment=exp, max_nb_epochs=30, train_percent_check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name        Type  Params\n",
      "0      gc_lstm  GCLSTMCell    6318\n",
      "1  gc_lstm.x2h      Linear    2808\n",
      "2  gc_lstm.h2h      Linear    2808\n",
      "3           fc      Linear      81\n",
      "4      dropout     Dropout       0\n",
      "y: torch.Size([6163, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/93 [01:19<41:48, 27.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: torch.Size([6163, 3])\n",
      "tensor([   4,    7,   16,  124,  157,  204,  351,  352,  379,  389,  430,  487,\n",
      "         492,  513,  539,  551,  568,  569,  587,  613,  630,  639,  649,  675,\n",
      "         680,  698,  711,  713,  780,  782,  784,  865, 1037, 1062, 1070, 1079,\n",
      "        1080, 1088, 1091, 1125, 1206, 1215, 1217, 1238, 1241, 1397, 1400, 1450,\n",
      "        1517, 1550, 1556, 1560, 1564, 1574, 1703, 1733, 1756, 1804, 1805, 1806,\n",
      "        1807, 1819, 1824, 1853, 1907, 1917, 1964, 1996, 1999, 2003, 2007, 2029,\n",
      "        2030, 2033, 2036, 2037, 2040, 2042, 2098, 2099, 2102, 2104, 2116, 2119,\n",
      "        2123, 2128, 2137, 2143, 2210, 2261, 2281, 2284, 2289, 2358, 2382, 2387,\n",
      "        2394, 2406, 2411, 2412, 2473, 2487, 2550, 2568, 2604, 2605, 2649, 2657,\n",
      "        2674, 2677, 2738, 2753, 2766, 2788, 2794, 2809, 2851, 2853, 2869, 2871,\n",
      "        2917, 2925, 2956, 3081, 3086, 3087, 3088, 3090, 3117, 3120, 3132, 3223,\n",
      "        3264, 3450, 3458, 3459, 3530, 3577, 3587, 3627, 3629, 3645, 3728, 3792,\n",
      "        3870, 3974, 3984, 3993, 4006, 4064, 4065, 4083, 4084, 4303, 4445, 4448,\n",
      "        4550, 4551, 4572, 4602, 4655, 4673, 4688, 4698, 4700, 4704, 4798, 4814,\n",
      "        4866, 4889, 4953, 4967, 4992, 5035, 5122, 5149, 5244, 5285, 5357, 5391,\n",
      "        5400, 5476, 5479, 5484, 5485, 5516, 5525, 5528, 5529, 5611, 5688, 5703,\n",
      "        5706, 5721, 5752, 5823, 5824, 5825, 5826, 5827, 5828, 5834, 5858, 5953,\n",
      "        5956, 5964, 5970, 5981, 5988, 6002, 6004, 6121, 6157])\n",
      "y: torch.Size([6163, 3])\n",
      "y_hat: torch.Size([6163, 3])\n",
      "tensor([   4,    7,   16,  124,  157,  204,  351,  352,  379,  389,  430,  487,\n",
      "         492,  513,  539,  551,  568,  569,  587,  613,  630,  639,  649,  675,\n",
      "         680,  698,  711,  713,  780,  782,  784,  865, 1037, 1062, 1070, 1079,\n",
      "        1080, 1088, 1091, 1125, 1206, 1215, 1217, 1238, 1241, 1397, 1400, 1450,\n",
      "        1517, 1550, 1556, 1560, 1564, 1574, 1703, 1733, 1756, 1804, 1805, 1806,\n",
      "        1807, 1819, 1824, 1853, 1907, 1917, 1964, 1996, 1999, 2003, 2007, 2029,\n",
      "        2030, 2033, 2036, 2037, 2040, 2042, 2098, 2099, 2102, 2104, 2116, 2119,\n",
      "        2123, 2128, 2137, 2143, 2210, 2261, 2281, 2284, 2289, 2358, 2382, 2387,\n",
      "        2394, 2406, 2411, 2412, 2473, 2487, 2550, 2568, 2604, 2605, 2649, 2657,\n",
      "        2674, 2677, 2738, 2753, 2766, 2788, 2794, 2809, 2851, 2853, 2869, 2871,\n",
      "        2917, 2925, 2956, 3081, 3086, 3087, 3088, 3090, 3117, 3120, 3132, 3223,\n",
      "        3264, 3450, 3458, 3459, 3530, 3577, 3587, 3627, 3629, 3645, 3728, 3792,\n",
      "        3870, 3974, 3984, 3993, 4006, 4064, 4065, 4083, 4084, 4303, 4445, 4448,\n",
      "        4550, 4551, 4572, 4602, 4655, 4673, 4688, 4698, 4700, 4704, 4798, 4814,\n",
      "        4866, 4889, 4953, 4967, 4992, 5035, 5122, 5149, 5244, 5285, 5357, 5391,\n",
      "        5400, 5476, 5479, 5484, 5485, 5516, 5525, 5528, 5529, 5611, 5688, 5703,\n",
      "        5706, 5721, 5752, 5823, 5824, 5825, 5826, 5827, 5828, 5834, 5858, 5953,\n",
      "        5956, 5964, 5970, 5981, 5988, 6002, 6004, 6121, 6157])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/93 [01:19<29:01, 19.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: torch.Size([6163, 3])\n",
      "y_hat: torch.Size([6163, 3])\n",
      "tensor([   4,    7,   16,  124,  157,  204,  351,  352,  379,  389,  430,  487,\n",
      "         492,  513,  539,  551,  568,  569,  587,  613,  630,  639,  649,  675,\n",
      "         680,  698,  711,  713,  780,  782,  784,  865, 1037, 1062, 1070, 1079,\n",
      "        1080, 1088, 1091, 1125, 1206, 1215, 1217, 1238, 1241, 1397, 1400, 1450,\n",
      "        1517, 1550, 1556, 1560, 1564, 1574, 1703, 1733, 1756, 1804, 1805, 1806,\n",
      "        1807, 1819, 1824, 1853, 1907, 1917, 1964, 1996, 1999, 2003, 2007, 2029,\n",
      "        2030, 2033, 2036, 2037, 2040, 2042, 2098, 2099, 2102, 2104, 2116, 2119,\n",
      "        2123, 2128, 2137, 2143, 2210, 2261, 2281, 2284, 2289, 2358, 2382, 2387,\n",
      "        2394, 2406, 2411, 2412, 2473, 2487, 2550, 2568, 2604, 2605, 2649, 2657,\n",
      "        2674, 2677, 2738, 2753, 2766, 2788, 2794, 2809, 2851, 2853, 2869, 2871,\n",
      "        2917, 2925, 2956, 3081, 3086, 3087, 3088, 3090, 3117, 3120, 3132, 3223,\n",
      "        3264, 3450, 3458, 3459, 3530, 3577, 3587, 3627, 3629, 3645, 3728, 3792,\n",
      "        3870, 3974, 3984, 3993, 4006, 4064, 4065, 4083, 4084, 4303, 4445, 4448,\n",
      "        4550, 4551, 4572, 4602, 4655, 4673, 4688, 4698, 4700, 4704, 4798, 4814,\n",
      "        4866, 4889, 4953, 4967, 4992, 5035, 5122, 5149, 5244, 5285, 5357, 5391,\n",
      "        5400, 5476, 5479, 5484, 5485, 5516, 5525, 5528, 5529, 5611, 5688, 5703,\n",
      "        5706, 5721, 5752, 5823, 5824, 5825, 5826, 5827, 5828, 5834, 5858, 5953,\n",
      "        5956, 5964, 5970, 5981, 5988, 6002, 6004, 6121, 6157])\n",
      "y: torch.Size([6163, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/93 [00:00<?, ?it/s].76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat: torch.Size([6163, 3])\n",
      "tensor([   4,    7,   16,  124,  157,  204,  351,  352,  379,  389,  430,  487,\n",
      "         492,  513,  539,  551,  568,  569,  587,  613,  630,  639,  649,  675,\n",
      "         680,  698,  711,  713,  780,  782,  784,  865, 1037, 1062, 1070, 1079,\n",
      "        1080, 1088, 1091, 1125, 1206, 1215, 1217, 1238, 1241, 1397, 1400, 1450,\n",
      "        1517, 1550, 1556, 1560, 1564, 1574, 1703, 1733, 1756, 1804, 1805, 1806,\n",
      "        1807, 1819, 1824, 1853, 1907, 1917, 1964, 1996, 1999, 2003, 2007, 2029,\n",
      "        2030, 2033, 2036, 2037, 2040, 2042, 2098, 2099, 2102, 2104, 2116, 2119,\n",
      "        2123, 2128, 2137, 2143, 2210, 2261, 2281, 2284, 2289, 2358, 2382, 2387,\n",
      "        2394, 2406, 2411, 2412, 2473, 2487, 2550, 2568, 2604, 2605, 2649, 2657,\n",
      "        2674, 2677, 2738, 2753, 2766, 2788, 2794, 2809, 2851, 2853, 2869, 2871,\n",
      "        2917, 2925, 2956, 3081, 3086, 3087, 3088, 3090, 3117, 3120, 3132, 3223,\n",
      "        3264, 3450, 3458, 3459, 3530, 3577, 3587, 3627, 3629, 3645, 3728, 3792,\n",
      "        3870, 3974, 3984, 3993, 4006, 4064, 4065, 4083, 4084, 4303, 4445, 4448,\n",
      "        4550, 4551, 4572, 4602, 4655, 4673, 4688, 4698, 4700, 4704, 4798, 4814,\n",
      "        4866, 4889, 4953, 4967, 4992, 5035, 5122, 5149, 5244, 5285, 5357, 5391,\n",
      "        5400, 5476, 5479, 5484, 5485, 5516, 5525, 5528, 5529, 5611, 5688, 5703,\n",
      "        5706, 5721, 5752, 5823, 5824, 5825, 5826, 5827, 5828, 5834, 5858, 5953,\n",
      "        5956, 5964, 5970, 5981, 5988, 6002, 6004, 6121, 6157])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 3: out of range at ../aten/src/TH/generic/THTensor.cpp:318",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-0486411601a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m model = TGCN(input_dim=26, hidden_dim=26, layer_dim=2, output_dim=3, adj=adj, \n\u001b[1;32m      9\u001b[0m              datasets=data, indices=indices)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# return 1 when finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__run_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# ---------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tng_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36mrun_tng_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mbatch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_tng_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0mearly_stop_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_result\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__run_tng_batch\u001b[0;34m(self, data_batch, batch_nb)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_specific_tqdm_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tng_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;31m# track metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__tng_forward\u001b[0;34m(self, data_batch, batch_nb, opt_idx)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/speed-imputation/src/tgcn/temporal_spatial_model.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_nb)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         return {'loss': F.mse_loss(torch.index_select(y_hat, dim=0, index=self.indices),\n\u001b[0;32m---> 88\u001b[0;31m                                    torch.index_select(y, dim=0, index=self.indices).float())}\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 3: out of range at ../aten/src/TH/generic/THTensor.cpp:318"
     ]
    }
   ],
   "source": [
    "import imp  \n",
    "import src.tgcn.temporal_spatial_model as l\n",
    "import src.tgcn.layers.lstmcell as h\n",
    "h = imp.reload(h)\n",
    "\n",
    "l = imp.reload(l)\n",
    "TGCN = l.TGCN\n",
    "model = TGCN(input_dim=26, hidden_dim=26, layer_dim=2, output_dim=3, adj=adj, \n",
    "             datasets=data, indices=indices)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
