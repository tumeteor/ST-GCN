{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.graph_utils import partition_graph_by_lonlat\n",
    "import networkx as nx\n",
    "from jurbey.jurbey import JURBEY\n",
    "\n",
    "with open(\"../data/1558537930325.jurbey\", 'rb') as tempf:\n",
    "    g = JURBEY.load(tempf.read())\n",
    "print(g.number_of_nodes())\n",
    "g_partition = partition_graph_by_lonlat(g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert to edge-based graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "L = nx.line_graph(nx.DiGraph(g_partition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arc(arcType=<ArcType.LANE_STRAIGHT: 'LANE_STRAIGHT'>, roadClass=<RoadClass.MajorRoad: 2>, roadAccessibility=<RoadAccessibility.NoRestriction: 1>, metadata={'bicycle': 'no', 'highway': 'primary', 'lanes': '4', 'lit': 'yes', 'maxspeed': '50', 'name': 'Bismarckstraße', 'oneway': 'yes', 'postal_code': '10625', 'ref': 'B 2;B 5', 'surface': 'asphalt', 'turn:lanes': 'through|through|through;right|right'}, signs=[], vehicleAccessibility=[], geometry=[GeoCoordinates(lon=13.3207077, lat=52.5123944, alt=nan), GeoCoordinates(lon=13.3207877, lat=52.5123711, alt=nan)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(L.nodes())\n",
    "g_partition[nodes[10][0]][nodes[10][1]]['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract dynamic (speed) + static features from nodes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = StandardScaler()\n",
    "def arc_features(arc):\n",
    "    arc = g_partition[arc[0]][arc[1]]\n",
    "    return [ \n",
    "        float(arc['data'].metadata.get('maxspeed', '50')), \n",
    "        arc['data'].metadata.get('lanes', '1'),\n",
    "        arc['data'].metadata['highway'],\n",
    "        arc['data'].metadata.get('surface', 'no_sur'),\n",
    "        arc['data'].roadClass.name,\n",
    "        arc['data'].roadAccessibility.name\n",
    "    ]\n",
    "def construct_features():\n",
    "    data = list()\n",
    "    for node in L.nodes:\n",
    "        data.append(arc_features(node))\n",
    "    return enc.fit_transform(data)\n",
    "    \n",
    "X = construct_features()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5.0, 10.0, 20.0, 30.0, 50.0], dtype=object),\n",
       " array(['1', '2', '3', '4', '5'], dtype=object),\n",
       " array(['access_ramp', 'corridor', 'living_street', 'platform', 'primary',\n",
       "        'residential', 'secondary', 'secondary_link', 'service',\n",
       "        'tertiary', 'tertiary_link', 'unclassified'], dtype=object),\n",
       " array(['asphalt', 'cobblestone', 'cobblestone:flattened', 'concrete',\n",
       "        'concrete:plates', 'grass_paver', 'no_sur', 'paved',\n",
       "        'paving_stones', 'sett'], dtype=object),\n",
       " array(['DirtRoad', 'LocalRoad', 'MajorRoad'], dtype=object),\n",
       " array(['NoRestriction'], dtype=object)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6163, 25)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess adjacency matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = nx.to_scipy_sparse_matrix(L, format=\"coo\")\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "                                    \n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "# build symmetric adjacency matrix\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "                                    \n",
    "adj = normalize(adj + sp.eye(adj.shape[0]))\n",
    "adj = sparse_mx_to_torch_sparse_tensor(adj)\n",
    "                                    \n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6163, 6163])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 7, 16, 124, 157, 204, 351, 352, 379, 389, 430, 487, 492, 513, 539, 551, 568, 569, 587, 613, 630, 639, 649, 675, 680, 698, 711, 713, 780, 782, 784, 865, 1037, 1062, 1070, 1079, 1080, 1088, 1091, 1125, 1206, 1215, 1217, 1238, 1241, 1397, 1400, 1450, 1517, 1550, 1556, 1560, 1564, 1574, 1703, 1733, 1756, 1804, 1805, 1806, 1807, 1819, 1824, 1853, 1907, 1917, 1964, 1996, 1999, 2003, 2007, 2029, 2030, 2033, 2036, 2037, 2040, 2042, 2098, 2099, 2102, 2104, 2116, 2119, 2123, 2128, 2137, 2143, 2210, 2261, 2281, 2284, 2289, 2358, 2382, 2387, 2394, 2406, 2411, 2412, 2473, 2487, 2550, 2568, 2604, 2605, 2649, 2657, 2674, 2677, 2738, 2753, 2766, 2788, 2794, 2809, 2851, 2853, 2869, 2871, 2917, 2925, 2956, 3081, 3086, 3087, 3088, 3090, 3117, 3120, 3132, 3223, 3264, 3450, 3458, 3459, 3530, 3577, 3587, 3627, 3629, 3645, 3728, 3792, 3870, 3974, 3984, 3993, 4006, 4064, 4065, 4083, 4084, 4303, 4445, 4448, 4550, 4551, 4572, 4602, 4655, 4673, 4688, 4698, 4700, 4704, 4798, 4814, 4866, 4889, 4953, 4967, 4992, 5035, 5122, 5149, 5244, 5285, 5357, 5391, 5400, 5476, 5479, 5484, 5485, 5516, 5525, 5528, 5529, 5611, 5688, 5703, 5706, 5721, 5752, 5823, 5824, 5825, 5826, 5827, 5828, 5834, 5858, 5953, 5956, 5964, 5970, 5981, 5988, 6002, 6004, 6121, 6157]\n"
     ]
    }
   ],
   "source": [
    "#Our speed data uses segment ids, but the model uses sequential indexes, based on `.nodes()`\n",
    "import math\n",
    "id_to_idx = {}\n",
    "# defaultdict won't do what you expect in Pandas\n",
    "df = pandas.read_csv(\"../data/timeseries_speed_april_first_week.csv\")\n",
    "df = df.T\n",
    "l = (df.isnull().mean() < 0.5).tolist()\n",
    "\n",
    "indices = [i for i, x in enumerate(l) if x == True]\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguytu3/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0          1          2          3          4          5  \\\n",
      "0  10.854457  10.854457  10.854457  10.854457   5.680978   5.680978   \n",
      "1  10.854457  10.854457  10.854457  10.854457   5.680978   5.680978   \n",
      "2  10.854457  10.854457  10.854457  10.854457  10.486210  10.486210   \n",
      "3  10.468811  10.468811  10.468811  10.468811  10.486210  10.486210   \n",
      "4  10.468811  10.468811  10.468811  10.468811  10.636621  10.288534   \n",
      "5  10.468811  10.468811  10.468811  10.468811  10.636621  10.288534   \n",
      "6  10.854457  10.854457  10.854457  10.854457  10.831409   5.680978   \n",
      "7  10.278846  10.854457  10.854457  10.854457  10.831409   5.680978   \n",
      "8  10.278846  10.854457  10.854457  10.854457  10.831409  10.298252   \n",
      "9  10.278846  10.854457  10.854457  10.854457  10.831409  10.298252   \n",
      "\n",
      "           6          7          8          9  ...        136        137  \\\n",
      "0   7.036838   1.499997  10.088634  10.587459  ...  10.581123  10.850843   \n",
      "1   7.036838   1.499997  10.088634  10.587459  ...  10.581123  10.850843   \n",
      "2   7.036838   1.499997  10.937218  10.587459  ...  10.581123  10.850843   \n",
      "3  10.617513   1.758539  10.937218  10.224568  ...   6.098767  10.392901   \n",
      "4  10.617513   1.758539   3.404401  10.224568  ...   6.098767  10.257657   \n",
      "5  10.286999   1.758539   3.404401  10.833570  ...  10.537584  10.286999   \n",
      "6   7.036838   1.499997   5.044317  10.587459  ...   0.961866  10.286999   \n",
      "7   3.140737   2.073876   0.385263   4.104480  ...  10.505827  10.517314   \n",
      "8   1.220956  10.298252   0.385263   4.104480  ...  10.505827  10.517314   \n",
      "9   1.220956  10.298252   0.385263   4.104480  ...  10.505827  10.517314   \n",
      "\n",
      "         138        139        140        141        142        143  \\\n",
      "0  10.850843  10.850843  10.850843  10.850843  10.850843  10.036408   \n",
      "1  10.850843  10.850843  10.850843  10.850843  10.850843  10.036408   \n",
      "2  10.850843  10.850843  10.850843  10.850843  10.850843  10.036408   \n",
      "3  10.392901  10.392901  10.392901  10.392901  10.392901  10.518310   \n",
      "4  10.586166  10.669476  10.669476   4.313417  10.392901  10.518310   \n",
      "5  10.586166  10.669476  10.669476   7.238553  10.497979  10.491733   \n",
      "6  10.586166  10.669476  10.669476   7.238553  10.850843  10.036408   \n",
      "7  10.586166  10.669476  10.669476  10.189923  10.436750   4.196431   \n",
      "8  10.586166  10.669476  10.669476  10.189923  10.436750   4.196431   \n",
      "9  10.586166  10.669476  10.669476  10.189923  10.436750   4.196431   \n",
      "\n",
      "    from_node     to_node  \n",
      "0   628154368  1023689595  \n",
      "1   628154368  1023689595  \n",
      "2   527147009    27537239  \n",
      "3   527147009    26908815  \n",
      "4   628154370  3804638178  \n",
      "5   628154372    26938222  \n",
      "6   628154375  1560866145  \n",
      "7  5791596551  1321327852  \n",
      "8  5791621141  4782446443  \n",
      "9  5791621141    26875019  \n",
      "\n",
      "[10 rows x 146 columns]\n"
     ]
    }
   ],
   "source": [
    "id_to_idx = {}\n",
    "\n",
    "for idx, id_ in enumerate(L.nodes()):\n",
    "    id_to_idx[id_] = idx\n",
    "df = df.T\n",
    "df = df.loc[:, df.columns != 'Unnamed: 0']\n",
    "df = df.convert_objects(convert_numeric=True)\n",
    "\n",
    "\n",
    "df2 = df['from_node']\n",
    "df3 = df['to_node']\n",
    "\n",
    "df_filled = df.loc[:, df.columns != 'from_node']\n",
    "df_filled = df.loc[:, df.columns != 'to_node']\n",
    "\n",
    "\n",
    "df_filled = df_filled.T\n",
    "for column in df_filled:\n",
    "    df_filled[column] = pandas.to_numeric(df_filled[column])\n",
    "\n",
    "df_filled = df_filled.interpolate(method='nearest', axis=1)\n",
    "\n",
    "df_filled = df_filled.fillna(method='backfill')\n",
    "df_filled = df_filled.T\n",
    "df_filled['from_node'] = df2\n",
    "df_filled['to_node'] = df3\n",
    "\n",
    "print(df_filled[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>10.088634</td>\n",
       "      <td>10.587459</td>\n",
       "      <td>...</td>\n",
       "      <td>10.581123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>10.088634</td>\n",
       "      <td>10.587459</td>\n",
       "      <td>...</td>\n",
       "      <td>10.581123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.937218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>27537239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>26908815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.636621</td>\n",
       "      <td>10.288534</td>\n",
       "      <td>10.617513</td>\n",
       "      <td>1.758539</td>\n",
       "      <td>3.404401</td>\n",
       "      <td>10.224568</td>\n",
       "      <td>...</td>\n",
       "      <td>6.098767</td>\n",
       "      <td>10.257657</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>4.313417</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.518310</td>\n",
       "      <td>628154370</td>\n",
       "      <td>3804638178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.286999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.833570</td>\n",
       "      <td>...</td>\n",
       "      <td>10.537584</td>\n",
       "      <td>10.286999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.238553</td>\n",
       "      <td>10.497979</td>\n",
       "      <td>10.491733</td>\n",
       "      <td>628154372</td>\n",
       "      <td>26938222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>5.044317</td>\n",
       "      <td>10.587459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154375</td>\n",
       "      <td>1560866145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.278846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.140737</td>\n",
       "      <td>2.073876</td>\n",
       "      <td>0.385263</td>\n",
       "      <td>4.104480</td>\n",
       "      <td>...</td>\n",
       "      <td>10.505827</td>\n",
       "      <td>10.517314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.189923</td>\n",
       "      <td>10.436750</td>\n",
       "      <td>4.196431</td>\n",
       "      <td>5791596551</td>\n",
       "      <td>1321327852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.298252</td>\n",
       "      <td>1.220956</td>\n",
       "      <td>10.298252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5791621141</td>\n",
       "      <td>4782446443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5791621141</td>\n",
       "      <td>26875019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0   1   2          3          4          5          6          7  \\\n",
       "0        NaN NaN NaN  10.854457        NaN   5.680978   7.036838   1.499997   \n",
       "1        NaN NaN NaN  10.854457        NaN   5.680978   7.036838   1.499997   \n",
       "2        NaN NaN NaN        NaN        NaN  10.486210        NaN        NaN   \n",
       "3        NaN NaN NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "4        NaN NaN NaN  10.468811  10.636621  10.288534  10.617513   1.758539   \n",
       "5        NaN NaN NaN        NaN        NaN        NaN  10.286999        NaN   \n",
       "6        NaN NaN NaN  10.854457        NaN   5.680978   7.036838   1.499997   \n",
       "7  10.278846 NaN NaN        NaN  10.831409        NaN   3.140737   2.073876   \n",
       "8        NaN NaN NaN        NaN        NaN  10.298252   1.220956  10.298252   \n",
       "9        NaN NaN NaN        NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "           8          9  ...        136        137        138  139        140  \\\n",
       "0  10.088634  10.587459  ...  10.581123        NaN        NaN  NaN        NaN   \n",
       "1  10.088634  10.587459  ...  10.581123        NaN        NaN  NaN        NaN   \n",
       "2  10.937218        NaN  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "3        NaN        NaN  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "4   3.404401  10.224568  ...   6.098767  10.257657  10.586166  NaN  10.669476   \n",
       "5        NaN  10.833570  ...  10.537584  10.286999        NaN  NaN        NaN   \n",
       "6   5.044317  10.587459  ...   0.961866        NaN        NaN  NaN        NaN   \n",
       "7   0.385263   4.104480  ...  10.505827  10.517314        NaN  NaN        NaN   \n",
       "8        NaN        NaN  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "9        NaN        NaN  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "\n",
       "         141        142        143   from_node     to_node  \n",
       "0        NaN  10.850843  10.036408   628154368  1023689595  \n",
       "1        NaN  10.850843  10.036408   628154368  1023689595  \n",
       "2        NaN        NaN        NaN   527147009    27537239  \n",
       "3        NaN        NaN        NaN   527147009    26908815  \n",
       "4   4.313417  10.392901  10.518310   628154370  3804638178  \n",
       "5   7.238553  10.497979  10.491733   628154372    26938222  \n",
       "6        NaN  10.850843  10.036408   628154375  1560866145  \n",
       "7  10.189923  10.436750   4.196431  5791596551  1321327852  \n",
       "8        NaN        NaN        NaN  5791621141  4782446443  \n",
       "9        NaN        NaN        NaN  5791621141    26875019  \n",
       "\n",
       "[10 rows x 146 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create rolling window tensor dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy.sparse\n",
    "TOTAL_T_STEPS = 144\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "def build_dataset_to_sparse_tensor(from_=0, to=TOTAL_T_STEPS):\n",
    "    dataset = list()\n",
    "    for t in range(from_, to):\n",
    "        features_at_t = [[50, '4', 'primary', 'MajorRoad']] * len(L.nodes)\n",
    "        for _, row in df.iterrows():\n",
    "            arc = (row['from_node'], row['to_node'])\n",
    "            features_at_t[id_to_idx[arc]] = arc_features(arc, speed=row[str(t)])        \n",
    "        dataset.append(sparse_mx_to_torch_sparse_tensor(enc.fit_transform(features_at_t)))\n",
    "    return torch.stack(dataset, dim=0)\n",
    "    \n",
    "def build_dataset_to_numpy_tensor(from_=0, to=TOTAL_T_STEPS, df=None):\n",
    "    dataset = list()\n",
    "    for t in range(from_, to):\n",
    "        cat_features_at_t = [[50, '4', 'primary', 'MajorRoad']] * len(L.nodes)\n",
    "        speed_features_at_t = [50] * len(L.nodes) \n",
    "        for _, row in df.iterrows():\n",
    "\n",
    "            arc = (row['from_node'], row['to_node'])\n",
    "            cat_features_at_t[id_to_idx[arc]] = arc_features(arc)\n",
    "            speed_features_at_t[id_to_idx[arc]] = row[str(t)]\n",
    "        dataset.append(np.concatenate([scaler.fit_transform(np.array(speed_features_at_t).reshape(-1, 1)), enc.fit_transform(cat_features_at_t).toarray()], axis=1))\n",
    "    return np.stack(dataset, axis=0)\n",
    "\n",
    "Y = build_dataset_to_numpy_tensor(df=df)\n",
    "Y_filled = build_dataset_to_numpy_tensor(df=df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 6163, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize the sparse tensor dataset\n",
    "# torch.save(X.indices(), \"../data/dataset_st_indices.pt\", pickle_protocol=4)\n",
    "# torch.save(X.values(), \"../data/dataset_st_values.pt\", pickle_protocol=4)\n",
    "# torch.save(X.size(), \"../data/dataset_st_size.pt\", pickle_protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6163, 26, 144)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.moveaxis(Y, source=(0,1,2), destination=(2,0,1))\n",
    "X_filled = np.moveaxis(Y_filled, source=(0,1,2), destination=(2,0,1))\n",
    "\n",
    "\n",
    "# num_vertices, num_features, num_timesteps\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6163, 26, 144)\n",
      "torch.Size([6163, 26, 144])\n"
     ]
    }
   ],
   "source": [
    "# Build mask tensor\n",
    "X_masked = torch.where(torch.isnan(torch.from_numpy(X)), torch.tensor([0]), torch.tensor([1]))\n",
    "X_masked = X_masked.bool()\n",
    "print(X.shape)\n",
    "print(X_masked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(X, num_timesteps_input, num_timesteps_output):\n",
    "    \"\"\"\n",
    "    Takes node features for the graph and divides them into multiple samples\n",
    "    along the time-axis by sliding a window of size (num_timesteps_input+\n",
    "    num_timesteps_output) across it in steps of 1.\n",
    "    :param X: Node features of shape (num_vertices, num_features,\n",
    "    num_timesteps)\n",
    "    :return:\n",
    "        - Node features divided into multiple samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_input).\n",
    "        - Node targets for the samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_output).\n",
    "    \"\"\"\n",
    "    # Generate the beginning index and the ending index of a sample, which\n",
    "    # contains (num_points_for_training + num_points_for_predicting) points\n",
    "    indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n",
    "               in range(X.shape[2] - (\n",
    "                num_timesteps_input + num_timesteps_output) + 1)]\n",
    "\n",
    "    # Save samples\n",
    "    features, target = [], []\n",
    "    for i, j in indices:\n",
    "        features.append(\n",
    "            X[:, :, i: i + num_timesteps_input])\n",
    "        target.append(X[:, :, i + num_timesteps_input: j])\n",
    "\n",
    "    return torch.from_numpy(np.array(features)).permute(0,1,3,2), \\\n",
    "           torch.from_numpy(np.array(target)).permute(0,1,3,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_dataset_concat(X, X_masked, num_timesteps_input, num_timesteps_output):\n",
    "    \"\"\"\n",
    "    Takes node features for the graph and divides them into multiple samples\n",
    "    along the time-axis by sliding a window of size (num_timesteps_input+\n",
    "    num_timesteps_output) across it in steps of 1.\n",
    "    :param X: Node features of shape (num_vertices, num_features,\n",
    "    num_timesteps)\n",
    "    :return:\n",
    "        - Node data (features + labels) divided into multiple samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_input).\n",
    "        \n",
    "    \"\"\"\n",
    "    # Generate the beginning index and the ending index of a sample, which\n",
    "    # contains (num_points_for_training + num_points_for_predicting) points\n",
    "    indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n",
    "               in range(X.shape[2] - (\n",
    "                num_timesteps_input + num_timesteps_output) + 1)]\n",
    "\n",
    "    # Save samples\n",
    "    dataset = []\n",
    "    mask = []\n",
    "    for i, j in indices:\n",
    "        dataset.append(X[:, :, i: j])\n",
    "        mask.append(X_masked[:, :, i: j])\n",
    "\n",
    "    return torch.from_numpy(np.array(dataset)), torch.stack(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training: torch.Size([91, 6163, 26, 10]), torch.Size([91, 6163, 26, 10])\n",
      "shape of validation: torch.Size([20, 6163, 26, 10]), torch.Size([20, 6163, 26, 10])\n",
      "shape of testing: torch.Size([6, 6163, 26, 10]), torch.Size([6, 6163, 26, 10])\n"
     ]
    }
   ],
   "source": [
    "# training, validation, testing : 0.7, 0.1, 0.2\n",
    "split_line1 = int(X.shape[2] * 0.7)\n",
    "split_line2 = int(X.shape[2] * 0.9)\n",
    "train_original_data = X_filled[:, :, :split_line1]\n",
    "val_original_data = X_filled[:, :, split_line1:split_line2]\n",
    "test_original_data = X_filled[:, :, split_line2:]\n",
    "\n",
    "train_mask = X_masked[:, :, :split_line1]\n",
    "valid_mask = X_masked[:, :, split_line1:split_line2]\n",
    "test_mask = X_masked[:, :, split_line2:]\n",
    "\n",
    "\n",
    "look_back = 9\n",
    "look_ahead = 1\n",
    "# num_samples, num_nodes, num_timesteps, num_features\n",
    "\n",
    "training_data, train_mask = generate_dataset_concat(train_original_data, train_mask,\n",
    "                                                       num_timesteps_input=look_back,\n",
    "                                                       num_timesteps_output=look_ahead)\n",
    "valid_data, valid_mask = generate_dataset_concat(val_original_data, valid_mask,\n",
    "                                             num_timesteps_input=look_back,\n",
    "                                             num_timesteps_output=look_ahead)\n",
    "test_data, test_mask = generate_dataset_concat(test_original_data, test_mask,\n",
    "                                               num_timesteps_input=look_back,\n",
    "                                               num_timesteps_output=look_ahead)\n",
    "\n",
    "print(f\"shape of training: {training_data.shape}, {train_mask.shape}\")\n",
    "print(f\"shape of validation: {valid_data.shape}, {valid_mask.shape}\")\n",
    "print(f\"shape of testing: {test_data.shape}, {test_mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6163, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mask[1, :, 0, 9:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 6163, 26, 10])\n",
      "tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        ...,\n",
      "        [False],\n",
      "        [ True],\n",
      "        [ True]])\n",
      "tensor([[ 1.0103],\n",
      "        [ 1.1195],\n",
      "        [ 1.1002],\n",
      "        ...,\n",
      "        [-1.1023],\n",
      "        [ 1.1352],\n",
      "        [-0.8349]], dtype=torch.float64)\n",
      "tensor([-1.7332e-02, -9.9638e-01, -9.8757e-01, -1.0694e+00, -1.1453e+00,\n",
      "        -1.0197e+00,  1.1636e+00,  1.1948e+00,  1.1324e+00,  1.1311e+00,\n",
      "         1.1352e+00,  1.1352e+00,  1.1352e+00, -9.1041e-01, -1.1507e+00,\n",
      "        -8.4501e-01, -9.9979e-01,  1.0871e+00,  1.1435e+00, -8.6723e-01,\n",
      "         1.1043e+00,  1.1688e+00,  1.1688e+00, -1.1635e+00, -1.1130e+00,\n",
      "         1.1810e+00,  1.1810e+00,  1.0910e+00,  1.0407e+00,  5.9843e-01,\n",
      "        -1.1102e+00,  1.0996e+00,  1.0945e+00, -8.5722e-01, -8.4220e-01,\n",
      "        -8.6300e-01, -8.6300e-01, -8.6300e-01,  1.1941e+00, -8.3498e-01,\n",
      "         1.1688e+00, -5.2789e-01, -1.1506e+00, -1.1132e+00,  1.0477e+00,\n",
      "         1.0477e+00,  1.0213e+00,  1.0213e+00,  1.0799e+00,  1.0799e+00,\n",
      "         1.1334e+00, -8.9372e-01,  1.0477e+00,  1.0477e+00,  1.0683e+00,\n",
      "         1.0683e+00,  1.1016e-02, -9.9293e-01, -1.1473e+00, -1.0501e+00,\n",
      "         1.1642e+00,  1.1687e+00,  1.1687e+00,  1.0941e+00, -1.7168e-01,\n",
      "        -9.1558e-01,  1.0763e+00,  1.0763e+00,  1.2776e-02,  1.1139e+00,\n",
      "         1.0763e+00,  1.0908e+00,  1.1114e+00,  1.1961e+00, -8.4966e-01,\n",
      "        -8.4966e-01,  1.0023e+00, -1.0505e+00,  1.0703e+00,  1.1257e+00,\n",
      "         1.0055e+00,  1.0055e+00, -8.6417e-01, -8.6417e-01, -7.7516e-01,\n",
      "         1.1672e+00, -8.6417e-01, -8.6417e-01, -1.1303e+00,  1.1364e+00,\n",
      "         1.1364e+00, -8.4966e-01,  7.6924e-02,  1.0055e+00,  1.1149e+00,\n",
      "         1.2003e+00,  1.1319e+00,  1.1195e+00, -9.6196e-01, -1.0140e+00,\n",
      "         5.5458e-01, -9.9556e-01, -1.1208e+00, -1.0008e+00,  1.1063e+00,\n",
      "         1.0070e+00,  1.0070e+00,  1.0946e+00, -1.1300e+00,  1.0799e+00,\n",
      "        -1.1727e+00, -8.6417e-01, -8.4966e-01, -8.4966e-01,  1.0683e+00,\n",
      "        -5.8262e-01, -8.6417e-01, -8.6417e-01,  1.0203e+00,  1.0551e+00,\n",
      "         1.1947e+00, -1.1023e+00,  4.7946e-01,  4.7946e-01,  3.9041e-02,\n",
      "        -8.4839e-01,  5.6417e-01,  3.8957e-01, -7.9317e-01, -9.5034e-01,\n",
      "         1.1030e+00,  1.1030e+00,  1.1030e+00,  1.1941e+00,  1.1258e+00,\n",
      "         1.1649e+00, -8.1763e-01, -8.1763e-01,  1.0589e+00,  1.0279e+00,\n",
      "         1.1759e+00,  1.1097e+00, -3.9883e-02, -1.0099e+00, -1.0099e+00,\n",
      "         1.0269e+00, -9.8494e-01, -8.9425e-01,  1.0070e+00,  2.6723e-02,\n",
      "        -1.8811e-01, -1.8811e-01, -1.1115e+00, -1.1727e+00,  1.0683e+00,\n",
      "         1.0683e+00, -1.0359e+00,  8.9884e-02, -1.0026e+00, -1.0026e+00,\n",
      "        -1.1727e+00, -1.1023e+00, -1.0815e+00, -5.6399e-01, -9.8271e-01,\n",
      "        -4.3767e-01, -7.9480e-01, -9.1660e-01, -2.1690e-01, -1.1539e+00,\n",
      "         1.0084e+00, -9.1434e-01, -9.5701e-01,  1.0070e+00,  1.0070e+00,\n",
      "        -8.1763e-01, -8.1763e-01, -8.1763e-01, -8.4788e-01, -1.0865e+00,\n",
      "        -8.7726e-01, -8.7726e-01, -8.3113e-01, -8.3113e-01, -1.0681e+00,\n",
      "        -9.7013e-01,  1.0227e+00,  1.0748e+00,  1.0382e+00,  1.0431e+00,\n",
      "         1.0382e+00, -1.0833e+00,  1.1178e+00, -8.2895e-01, -1.1490e+00,\n",
      "        -8.1763e-01, -1.1727e+00, -8.1296e-01,  1.0070e+00, -8.0551e-01,\n",
      "        -8.0551e-01, -1.0300e+00,  1.1978e+00,  1.1978e+00,  1.0070e+00,\n",
      "         1.0419e+00,  5.4344e-02,  1.0070e+00, -5.9937e-02,  1.0745e+00,\n",
      "         1.0070e+00,  1.0913e+00,  1.0529e+00, -8.8499e-01,  1.1688e+00,\n",
      "         1.1688e+00, -8.8643e-01,  1.1688e+00,  1.1688e+00,  1.0133e+00,\n",
      "        -4.3165e-01, -1.0887e+00,  1.0683e+00,  1.0683e+00, -1.0451e+00,\n",
      "        -1.1539e+00, -1.1539e+00, -1.1539e+00, -8.0551e-01, -7.5394e-01,\n",
      "        -9.3984e-01, -8.4909e-01,  8.6954e-02, -8.8856e-01, -8.8856e-01,\n",
      "        -1.0519e+00, -1.0941e+00,  1.0793e+00,  1.0793e+00,  1.1153e+00,\n",
      "        -6.9267e-01,  3.1999e-01, -1.1165e+00,  8.3964e-02,  8.3964e-02,\n",
      "        -1.1539e+00, -1.0375e+00, -8.6417e-01,  1.0073e+00,  1.7498e-01,\n",
      "         1.7498e-01, -1.0021e+00, -1.0469e+00, -1.0300e+00, -8.4966e-01,\n",
      "        -8.4966e-01,  1.0683e+00,  1.0683e+00,  7.9940e-01,  1.2003e+00,\n",
      "         1.1442e+00, -8.9524e-01,  1.0558e+00,  1.0558e+00,  1.1688e+00,\n",
      "         1.1688e+00,  8.1879e-02,  8.1879e-02, -8.8630e-01,  9.7395e-02,\n",
      "         1.1941e+00,  1.1539e+00,  1.1539e+00, -1.0257e+00, -9.2313e-01,\n",
      "        -8.0870e-01, -1.1047e+00, -9.6197e-01, -9.6197e-01,  1.0360e+00,\n",
      "         9.9232e-01, -9.9638e-01, -9.6197e-01, -9.6197e-01, -9.6197e-01,\n",
      "         1.0641e+00, -9.6197e-01, -9.9638e-01, -1.0962e+00, -1.0257e+00,\n",
      "         1.1810e+00,  1.1810e+00, -8.7495e-01, -1.0885e+00, -1.0984e+00,\n",
      "        -1.0714e+00,  1.1526e+00, -1.0932e+00,  1.0431e+00,  1.0382e+00,\n",
      "         1.0936e+00, -1.1727e+00, -1.0451e+00,  1.1852e+00,  1.1356e+00,\n",
      "         1.1387e+00, -1.1042e+00, -8.5286e-01, -1.0267e+00, -1.1088e+00,\n",
      "        -1.1727e+00, -1.0347e+00,  1.1352e+00,  1.5877e-01, -9.8446e-01,\n",
      "        -8.5331e-01,  9.6370e+00, -2.0301e-01, -2.0301e-01, -8.7152e-01,\n",
      "        -1.1727e+00, -1.1186e+00, -1.1727e+00, -1.1690e+00, -1.1539e+00,\n",
      "         1.1760e+00,  1.0250e+00,  1.0250e+00,  1.1265e+00,  1.0254e+00,\n",
      "         1.1265e+00, -1.0967e+00, -1.1562e+00, -8.8191e-01, -8.8030e-01,\n",
      "        -1.1430e+00,  1.0055e+00,  1.0134e+00,  8.4357e-02, -8.6417e-01,\n",
      "        -8.6417e-01, -1.1727e+00, -1.1727e+00, -1.0026e+00,  1.0799e+00,\n",
      "        -1.0026e+00,  1.1649e+00, -1.1664e+00, -1.1400e+00, -7.6706e-01,\n",
      "         1.1847e+00,  1.0508e+00,  7.6924e-02,  1.0230e+00,  1.0230e+00,\n",
      "         1.0683e+00,  1.0683e+00,  1.0230e+00,  1.1285e+00, -8.6417e-01,\n",
      "        -9.5907e-01, -8.5224e-01, -1.0943e+00, -9.7150e-01, -1.0300e+00,\n",
      "        -8.5258e-01, -8.8856e-01, -8.7931e-01, -1.0140e+00,  1.0888e+00,\n",
      "        -8.9197e-01, -8.4966e-01,  1.1810e+00, -2.8907e-02, -7.8932e-01,\n",
      "         1.1810e+00,  1.1810e+00,  1.0173e+00,  1.0683e+00,  1.0254e+00,\n",
      "         1.0683e+00,  1.0683e+00, -1.0574e+00,  1.0683e+00, -8.9524e-01,\n",
      "        -8.9524e-01, -4.1352e-02,  1.0910e+00,  1.0407e+00, -8.1832e-01,\n",
      "        -8.9524e-01, -1.0161e+00,  1.1094e+00,  1.1094e+00, -8.6417e-01,\n",
      "         1.1334e+00, -8.6417e-01, -1.0493e+00,  1.0558e+00, -8.0474e-01,\n",
      "        -8.4591e-01, -1.1539e+00,  1.0683e+00,  1.0485e+00, -8.1504e-01,\n",
      "         1.1250e+00,  3.1765e-01, -1.0200e+00, -8.5095e-01, -8.0551e-01,\n",
      "         1.0683e+00, -9.8476e-01, -9.8476e-01, -2.9887e-01,  1.1810e+00,\n",
      "        -8.4788e-01, -8.4050e-01, -1.1649e+00, -1.0158e+00, -1.0805e+00,\n",
      "         1.1930e+00,  1.1207e+00,  1.0230e+00, -8.5314e-01,  1.0683e+00,\n",
      "        -8.8856e-01, -4.1630e-01, -6.7282e-01, -1.1649e+00,  1.0230e+00,\n",
      "         1.0230e+00,  1.2042e+00,  1.2042e+00,  1.0070e+00,  9.9690e-01,\n",
      "        -7.4874e-01,  1.1139e+00, -7.4874e-01, -1.1727e+00,  9.4468e-02,\n",
      "        -1.1727e+00, -6.0253e-01,  1.1122e+00,  1.1760e+00, -1.0914e+00,\n",
      "        -1.1539e+00, -4.3165e-01,  1.0745e+00, -8.8856e-01, -1.0161e+00,\n",
      "        -1.0161e+00,  9.5131e-02,  9.5131e-02,  1.1810e+00,  1.1810e+00,\n",
      "         1.0683e+00,  1.0703e+00, -1.1727e+00,  1.1364e+00,  1.1364e+00,\n",
      "        -1.7504e-01,  1.0703e+00,  3.5900e-02,  9.9690e-01,  3.5900e-02,\n",
      "         9.9690e-01,  3.5900e-02,  9.9690e-01,  1.1688e+00,  1.1688e+00,\n",
      "         3.1069e-01,  1.0641e+00, -9.9638e-01, -1.1363e+00, -1.1165e+00,\n",
      "        -3.2063e-01, -9.9638e-01, -9.7918e-01,  1.0797e+00, -9.9638e-01,\n",
      "        -8.9883e-01, -1.1727e+00, -1.0634e+00,  1.0070e+00,  1.0070e+00,\n",
      "         9.5131e-02,  1.0900e+00,  1.1086e+00,  1.1684e+00, -9.3057e-01,\n",
      "        -5.9163e-01,  1.0254e+00,  1.0254e+00, -8.4968e-01,  1.1688e+00,\n",
      "        -9.9513e-01,  1.1688e+00,  1.0230e+00, -8.3553e-01,  1.0287e-01,\n",
      "        -7.6603e-01,  1.1030e+00, -7.6603e-01,  1.0173e+00,  1.2042e+00,\n",
      "        -1.0099e+00, -9.6197e-01,  9.5131e-02, -1.1365e+00, -9.7851e-01,\n",
      "         1.1688e+00,  1.7335e-02, -1.0756e+00,  1.1688e+00,  9.6370e+00,\n",
      "         1.1352e+00,  1.1352e+00,  1.1352e+00, -1.0400e+00,  1.1779e+00,\n",
      "        -5.4898e-01,  9.1021e-02, -8.1763e-01,  1.0070e+00, -1.8811e-01,\n",
      "        -8.6462e-01,  1.1119e+00, -9.0838e-03,  1.1283e+00,  1.0882e+00,\n",
      "        -1.1727e+00, -1.1065e+00, -7.5694e-01, -7.5694e-01, -7.5694e-01,\n",
      "         4.4500e-01,  8.6954e-02,  1.1810e+00, -8.4909e-01, -9.5541e-01,\n",
      "        -8.0263e-01,  1.1539e+00, -9.4018e-01,  1.0230e+00, -8.4909e-01,\n",
      "         1.1030e+00, -1.0451e+00, -1.0451e+00, -7.7516e-01, -9.5931e-01,\n",
      "        -1.0107e+00, -9.8271e-01, -9.3056e-01, -1.1606e+00, -8.4909e-01,\n",
      "         1.0934e+00,  1.0934e+00, -1.1727e+00, -1.0128e+00, -1.1190e+00,\n",
      "        -1.0886e+00, -9.9151e-01,  1.1784e+00, -1.1727e+00, -8.0474e-01,\n",
      "        -9.8271e-01, -8.7257e-01, -1.1203e+00, -7.7516e-01,  1.0290e+00,\n",
      "        -8.9524e-01,  9.7395e-02,  1.0055e+00, -2.1690e-01, -7.5694e-01,\n",
      "         1.0906e+00,  1.0230e+00,  1.1122e+00,  1.1294e+00,  1.1192e+00,\n",
      "        -9.3059e-01,  8.6954e-02,  1.1265e+00, -9.4825e-01,  1.1810e+00,\n",
      "        -9.7986e-01, -1.1727e+00, -7.6753e-01, -1.0501e+00,  1.1914e+00,\n",
      "        -1.0911e+00,  1.1328e+00, -8.4355e-01,  1.1810e+00, -1.1727e+00,\n",
      "        -1.1720e+00, -1.0578e+00, -8.6300e-01, -9.6687e-01,  1.1192e+00,\n",
      "        -8.3113e-01, -8.3113e-01, -8.3113e-01,  1.0910e+00,  2.7783e-01,\n",
      "        -1.0973e+00, -1.0714e+00, -8.4355e-01,  1.0070e+00,  1.0070e+00,\n",
      "         1.1810e+00, -1.1505e+00,  1.1352e+00, -8.3491e-01],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "data['train'] = training_data\n",
    "data['valid'] = valid_data\n",
    "data['test'] = test_data\n",
    "\n",
    "mask = {}\n",
    "mask['train'] = train_mask\n",
    "mask['valid'] = valid_mask\n",
    "mask['test'] = test_mask\n",
    "# batch shape: torch.Size([1, 6163, 26, 10])\n",
    "print(valid_data.shape)\n",
    "print(valid_mask[0, :, 0, 9:])\n",
    "print(valid_data[0, :, 0, 9:])\n",
    "\n",
    "print(valid_data[0, :, 0, 9:].masked_select(valid_mask[0, :, 0, 9:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now start training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: False, used: False\n"
     ]
    }
   ],
   "source": [
    "from test_tube import Experiment \n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "\n",
    "# PyTorch summarywriter with a few bells and whistles    \n",
    "exp = Experiment(save_dir=os.getcwd())\n",
    "\n",
    "# pass in experiment for automatic tensorboard logging.    \n",
    "trainer = Trainer(experiment=exp, max_nb_epochs=30, train_percent_check=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▊    | 65/111 [00:39<05:22,  7.01s/it, avg_val_loss=1.51, batch_nb=62, epoch=5, tng_loss=1.619, v_nb=29]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Name        Type  Params\n",
      "0      gc_lstm  GCLSTMCell    6318\n",
      "1  gc_lstm.x2h      Linear    2808\n",
      "2  gc_lstm.h2h      Linear    2808\n",
      "3           fc      Linear      27\n",
      "4      dropout     Dropout       0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 26/111 [00:06<00:22,  3.79it/s, avg_val_loss=0.821, batch_nb=24, epoch=23, tng_loss=0.859, v_nb=29]]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-f214c2a0fc59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m model = TGCN(input_dim=26, hidden_dim=26, layer_dim=2, output_dim=1, adj=adj, \n\u001b[1;32m      9\u001b[0m              datasets=data, mask=mask)\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# return 1 when finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__run_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;31m# ---------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_tng_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36mrun_tng_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;31m# RUN TRAIN STEP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0mbatch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__run_tng_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0mearly_stop_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_result\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__run_tng_batch\u001b[0;34m(self, data_batch, batch_nb)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_specific_tqdm_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__tng_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0;31m# track metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_lightning/models/trainer.py\u001b[0m in \u001b[0;36m__tng_forward\u001b[0;34m(self, data_batch, batch_nb, opt_idx)\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;31m# ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/speed-imputation/src/tgcn/temporal_spatial_model.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_nb)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0m_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_nb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/speed-imputation/src/tgcn/temporal_spatial_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/speed-imputation/src/tgcn/layers/lstmcell.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hx, cx)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msupport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import imp  \n",
    "import src.tgcn.temporal_spatial_model as l\n",
    "import src.tgcn.layers.lstmcell as h\n",
    "h = imp.reload(h)\n",
    "\n",
    "l = imp.reload(l)\n",
    "TGCN = l.TGCN\n",
    "model = TGCN(input_dim=26, hidden_dim=26, layer_dim=2, output_dim=1, adj=adj, \n",
    "             datasets=data, mask=mask)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
