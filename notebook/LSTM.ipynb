{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290100\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.graph_utils import partition_graph_by_lonlat\n",
    "import networkx as nx\n",
    "from jurbey.jurbey import JURBEY\n",
    "\n",
    "with open(\"../data/berlin.jurbey\", 'rb') as tempf:\n",
    "    g = JURBEY.load(tempf.read())\n",
    "print(g.number_of_nodes())\n",
    "g_partition = partition_graph_by_lonlat(g)\n",
    "\n",
    "A = nx.adjacency_matrix(g_partition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>from_node</th>\n",
       "      <th>to_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>10.088634</td>\n",
       "      <td>...</td>\n",
       "      <td>10.581123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.854457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.680978</td>\n",
       "      <td>7.036838</td>\n",
       "      <td>1.499997</td>\n",
       "      <td>10.088634</td>\n",
       "      <td>...</td>\n",
       "      <td>10.581123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.850843</td>\n",
       "      <td>10.036408</td>\n",
       "      <td>628154368</td>\n",
       "      <td>1023689595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.486210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.937218</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>27537239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527147009</td>\n",
       "      <td>26908815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result.average</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.636621</td>\n",
       "      <td>10.288534</td>\n",
       "      <td>10.617513</td>\n",
       "      <td>1.758539</td>\n",
       "      <td>3.404401</td>\n",
       "      <td>...</td>\n",
       "      <td>6.098767</td>\n",
       "      <td>10.257657</td>\n",
       "      <td>10.586166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.669476</td>\n",
       "      <td>4.313417</td>\n",
       "      <td>10.392901</td>\n",
       "      <td>10.518310</td>\n",
       "      <td>628154370</td>\n",
       "      <td>3804638178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   0   1   2          3          4          5          6  \\\n",
       "0  result.average NaN NaN NaN  10.854457        NaN   5.680978   7.036838   \n",
       "1  result.average NaN NaN NaN  10.854457        NaN   5.680978   7.036838   \n",
       "2  result.average NaN NaN NaN        NaN        NaN  10.486210        NaN   \n",
       "3  result.average NaN NaN NaN        NaN        NaN        NaN        NaN   \n",
       "4  result.average NaN NaN NaN  10.468811  10.636621  10.288534  10.617513   \n",
       "\n",
       "          7          8  ...        136        137        138  139        140  \\\n",
       "0  1.499997  10.088634  ...  10.581123        NaN        NaN  NaN        NaN   \n",
       "1  1.499997  10.088634  ...  10.581123        NaN        NaN  NaN        NaN   \n",
       "2       NaN  10.937218  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "3       NaN        NaN  ...        NaN        NaN        NaN  NaN        NaN   \n",
       "4  1.758539   3.404401  ...   6.098767  10.257657  10.586166  NaN  10.669476   \n",
       "\n",
       "        141        142        143  from_node     to_node  \n",
       "0       NaN  10.850843  10.036408  628154368  1023689595  \n",
       "1       NaN  10.850843  10.036408  628154368  1023689595  \n",
       "2       NaN        NaN        NaN  527147009    27537239  \n",
       "3       NaN        NaN        NaN  527147009    26908815  \n",
       "4  4.313417  10.392901  10.518310  628154370  3804638178  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "id_to_idx = {}\n",
    "df = pandas.read_csv(\"../data/timeseries_speed_april_first_week.csv\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (6162, 147). Missing in data: 818224.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of data: {df.shape}. Missing in data: {df.isnull().sum().sum()}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove road segments with > 50% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original number of road segment: 6162\n",
      "original number of road segment after filtering: 213\n",
      "           0        1    2        3        4        5          6         7  \\\n",
      "4        NaN      NaN  NaN  10.4688  10.6366  10.2885    10.6175   1.75854   \n",
      "7    10.2788      NaN  NaN      NaN  10.8314      NaN    3.14074   2.07388   \n",
      "16   10.8814      NaN  NaN      NaN  10.9489  10.1905    8.48206   10.6813   \n",
      "124  10.2644      NaN  NaN  10.5666      NaN  7.37511   0.915255   10.1382   \n",
      "157      NaN      NaN  NaN      NaN  10.8314      NaN    7.53377   5.43425   \n",
      "204      NaN  10.0555  NaN      NaN      NaN      NaN  0.0954053    10.709   \n",
      "351      NaN      NaN  NaN  10.4688  10.4049  7.20193    7.68655   7.31936   \n",
      "352      NaN      NaN  NaN   10.471  10.3797  0.40066   0.149782  0.486138   \n",
      "379  10.3584      NaN  NaN      NaN  10.6964  6.91769    5.38908   10.8364   \n",
      "389      NaN      NaN  NaN  10.4688    10.38   7.0872    8.65096   10.2432   \n",
      "\n",
      "            8        9  ...      134        135      136      137      138  \\\n",
      "4      3.4044  10.2246  ...      NaN        NaN  6.09877  10.2577  10.5862   \n",
      "7    0.385263  4.10448  ...      NaN    10.3951  10.5058  10.5173      NaN   \n",
      "16    5.02823    10.55  ...      NaN        NaN  1.14562   7.3679  1.86871   \n",
      "124   1.44351  1.39497  ...  10.2675    10.9493  10.3746  5.40854      NaN   \n",
      "157   10.7573  10.3509  ...      NaN     5.1058   10.129  10.5877      NaN   \n",
      "204   2.71381  10.9534  ...  4.06558    1.87949  10.1904  4.34556  2.70244   \n",
      "351   5.89438  10.2791  ...      NaN  0.0382477  8.33314  10.3388  10.4677   \n",
      "352   1.70013   10.035  ...      NaN    10.3263  10.5539  10.3388  10.6167   \n",
      "379   7.80984  10.5734  ...  10.5366    5.21668  10.7039    10.72  10.5938   \n",
      "389   8.31396  10.2003  ...      NaN  0.0382477  8.33314  10.3062  10.5862   \n",
      "\n",
      "         139      140      141       142      143  \n",
      "4        NaN  10.6695  4.31342   10.3929  10.5183  \n",
      "7        NaN      NaN  10.1899   10.4367  4.19643  \n",
      "16   10.6086  10.3597      NaN       NaN  10.5958  \n",
      "124      NaN      NaN      NaN    10.607  10.3052  \n",
      "157  10.7772  10.7558      NaN    10.811  10.4329  \n",
      "204  10.5475  10.5027  10.5904   3.02929    10.82  \n",
      "351      NaN  10.6695   5.7017   10.4506  10.4078  \n",
      "352      NaN  10.6928  8.17036  0.921596      NaN  \n",
      "379  10.5717      NaN  7.23857    10.498    10.42  \n",
      "389  10.2744  10.6695   5.7017   10.6606  10.4951  \n",
      "\n",
      "[10 rows x 144 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/timeseries_speed_april_first_week.csv\")\n",
    "\n",
    "\n",
    "df = df.T\n",
    "print(f\"original number of road segment: {df.shape[1]}\")\n",
    "df = df.loc[:, df.isnull().mean() < 0.5]\n",
    "print(f\"original number of road segment after filtering: {df.shape[1]}\")\n",
    "df = df.T\n",
    "df = df.loc[:, df.columns != 'Unnamed: 0']\n",
    "df = df.loc[:, df.columns != 'from_node']\n",
    "df = df.loc[:, df.columns != 'to_node']\n",
    "print(df[0:10])\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate misisng values with Krogh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>7</th>\n",
       "      <th>16</th>\n",
       "      <th>124</th>\n",
       "      <th>157</th>\n",
       "      <th>204</th>\n",
       "      <th>351</th>\n",
       "      <th>352</th>\n",
       "      <th>379</th>\n",
       "      <th>389</th>\n",
       "      <th>...</th>\n",
       "      <th>5953</th>\n",
       "      <th>5956</th>\n",
       "      <th>5964</th>\n",
       "      <th>5970</th>\n",
       "      <th>5981</th>\n",
       "      <th>5988</th>\n",
       "      <th>6002</th>\n",
       "      <th>6004</th>\n",
       "      <th>6121</th>\n",
       "      <th>6157</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.278846</td>\n",
       "      <td>10.881422</td>\n",
       "      <td>10.264438</td>\n",
       "      <td>10.264438</td>\n",
       "      <td>10.264438</td>\n",
       "      <td>10.358411</td>\n",
       "      <td>10.358411</td>\n",
       "      <td>10.358411</td>\n",
       "      <td>10.358411</td>\n",
       "      <td>...</td>\n",
       "      <td>10.670639</td>\n",
       "      <td>10.670639</td>\n",
       "      <td>10.670639</td>\n",
       "      <td>10.670639</td>\n",
       "      <td>10.670639</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.446166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.055472</td>\n",
       "      <td>10.359838</td>\n",
       "      <td>10.359838</td>\n",
       "      <td>10.359838</td>\n",
       "      <td>10.359838</td>\n",
       "      <td>...</td>\n",
       "      <td>10.249640</td>\n",
       "      <td>10.249640</td>\n",
       "      <td>10.249640</td>\n",
       "      <td>10.249640</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.523302</td>\n",
       "      <td>10.446166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.471016</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>...</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "      <td>3.183892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.566648</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.471016</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>10.468811</td>\n",
       "      <td>...</td>\n",
       "      <td>5.404969</td>\n",
       "      <td>5.404969</td>\n",
       "      <td>6.499586</td>\n",
       "      <td>6.499586</td>\n",
       "      <td>10.489977</td>\n",
       "      <td>10.489977</td>\n",
       "      <td>5.641341</td>\n",
       "      <td>1.774943</td>\n",
       "      <td>6.938167</td>\n",
       "      <td>6.938167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.636621</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>10.948903</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>10.831409</td>\n",
       "      <td>10.404854</td>\n",
       "      <td>10.379701</td>\n",
       "      <td>10.696351</td>\n",
       "      <td>10.380026</td>\n",
       "      <td>...</td>\n",
       "      <td>4.587224</td>\n",
       "      <td>1.906247</td>\n",
       "      <td>0.421084</td>\n",
       "      <td>0.421084</td>\n",
       "      <td>10.896709</td>\n",
       "      <td>10.346092</td>\n",
       "      <td>4.223832</td>\n",
       "      <td>0.390303</td>\n",
       "      <td>2.033530</td>\n",
       "      <td>2.033530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.288534</td>\n",
       "      <td>10.288534</td>\n",
       "      <td>10.190479</td>\n",
       "      <td>7.375108</td>\n",
       "      <td>7.375108</td>\n",
       "      <td>7.375108</td>\n",
       "      <td>7.201934</td>\n",
       "      <td>0.400660</td>\n",
       "      <td>6.917693</td>\n",
       "      <td>7.087202</td>\n",
       "      <td>...</td>\n",
       "      <td>1.704999</td>\n",
       "      <td>1.285552</td>\n",
       "      <td>10.338850</td>\n",
       "      <td>0.655349</td>\n",
       "      <td>7.138202</td>\n",
       "      <td>0.115042</td>\n",
       "      <td>1.362726</td>\n",
       "      <td>0.149050</td>\n",
       "      <td>10.398745</td>\n",
       "      <td>1.690993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.617513</td>\n",
       "      <td>3.140737</td>\n",
       "      <td>8.482057</td>\n",
       "      <td>0.915255</td>\n",
       "      <td>7.533769</td>\n",
       "      <td>0.095405</td>\n",
       "      <td>7.686549</td>\n",
       "      <td>0.149782</td>\n",
       "      <td>5.389075</td>\n",
       "      <td>8.650964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.658714</td>\n",
       "      <td>4.124535</td>\n",
       "      <td>0.509908</td>\n",
       "      <td>7.888281</td>\n",
       "      <td>6.685049</td>\n",
       "      <td>0.765714</td>\n",
       "      <td>1.420218</td>\n",
       "      <td>10.531851</td>\n",
       "      <td>0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.758539</td>\n",
       "      <td>2.073876</td>\n",
       "      <td>10.681286</td>\n",
       "      <td>10.138236</td>\n",
       "      <td>5.434254</td>\n",
       "      <td>10.709016</td>\n",
       "      <td>7.319358</td>\n",
       "      <td>0.486138</td>\n",
       "      <td>10.836391</td>\n",
       "      <td>10.243176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.547999</td>\n",
       "      <td>1.275324</td>\n",
       "      <td>10.092655</td>\n",
       "      <td>0.989406</td>\n",
       "      <td>10.486895</td>\n",
       "      <td>9.096087</td>\n",
       "      <td>1.170159</td>\n",
       "      <td>0.500815</td>\n",
       "      <td>2.105265</td>\n",
       "      <td>0.413589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.404401</td>\n",
       "      <td>0.385263</td>\n",
       "      <td>5.028228</td>\n",
       "      <td>1.443512</td>\n",
       "      <td>10.757339</td>\n",
       "      <td>2.713814</td>\n",
       "      <td>5.894384</td>\n",
       "      <td>1.700133</td>\n",
       "      <td>7.809842</td>\n",
       "      <td>8.313960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469963</td>\n",
       "      <td>0.469963</td>\n",
       "      <td>10.605759</td>\n",
       "      <td>1.232956</td>\n",
       "      <td>8.237365</td>\n",
       "      <td>2.376006</td>\n",
       "      <td>4.479992</td>\n",
       "      <td>1.920087</td>\n",
       "      <td>1.315475</td>\n",
       "      <td>1.315475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.224568</td>\n",
       "      <td>4.104480</td>\n",
       "      <td>10.550042</td>\n",
       "      <td>1.394967</td>\n",
       "      <td>10.350923</td>\n",
       "      <td>10.953392</td>\n",
       "      <td>10.279088</td>\n",
       "      <td>10.034991</td>\n",
       "      <td>10.573360</td>\n",
       "      <td>10.200276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235419</td>\n",
       "      <td>2.096244</td>\n",
       "      <td>1.971357</td>\n",
       "      <td>1.454085</td>\n",
       "      <td>10.247256</td>\n",
       "      <td>10.665007</td>\n",
       "      <td>1.806557</td>\n",
       "      <td>0.668753</td>\n",
       "      <td>10.559178</td>\n",
       "      <td>0.814330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 213 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        4          7          16         124        157        204   \\\n",
       "0  10.468811  10.278846  10.881422  10.264438  10.264438  10.264438   \n",
       "1  10.468811  10.468811  10.468811  10.566648  10.566648  10.055472   \n",
       "2  10.468811  10.468811  10.468811  10.566648  10.566648  10.566648   \n",
       "3  10.468811  10.468811  10.468811  10.566648  10.566648  10.566648   \n",
       "4  10.636621  10.831409  10.948903  10.831409  10.831409  10.831409   \n",
       "5  10.288534  10.288534  10.190479   7.375108   7.375108   7.375108   \n",
       "6  10.617513   3.140737   8.482057   0.915255   7.533769   0.095405   \n",
       "7   1.758539   2.073876  10.681286  10.138236   5.434254  10.709016   \n",
       "8   3.404401   0.385263   5.028228   1.443512  10.757339   2.713814   \n",
       "9  10.224568   4.104480  10.550042   1.394967  10.350923  10.953392   \n",
       "\n",
       "        351        352        379        389   ...       5953       5956  \\\n",
       "0  10.358411  10.358411  10.358411  10.358411  ...  10.670639  10.670639   \n",
       "1  10.359838  10.359838  10.359838  10.359838  ...  10.249640  10.249640   \n",
       "2  10.468811  10.471016  10.468811  10.468811  ...   3.183892   3.183892   \n",
       "3  10.468811  10.471016  10.468811  10.468811  ...   5.404969   5.404969   \n",
       "4  10.404854  10.379701  10.696351  10.380026  ...   4.587224   1.906247   \n",
       "5   7.201934   0.400660   6.917693   7.087202  ...   1.704999   1.285552   \n",
       "6   7.686549   0.149782   5.389075   8.650964  ...   0.000000   0.658714   \n",
       "7   7.319358   0.486138  10.836391  10.243176  ...   1.547999   1.275324   \n",
       "8   5.894384   1.700133   7.809842   8.313960  ...   0.469963   0.469963   \n",
       "9  10.279088  10.034991  10.573360  10.200276  ...   0.235419   2.096244   \n",
       "\n",
       "        5964       5970       5981       5988       6002       6004  \\\n",
       "0  10.670639  10.670639  10.670639  10.523302  10.523302  10.523302   \n",
       "1  10.249640  10.249640  10.523302  10.523302  10.523302  10.523302   \n",
       "2   3.183892   3.183892   3.183892   3.183892   3.183892   3.183892   \n",
       "3   6.499586   6.499586  10.489977  10.489977   5.641341   1.774943   \n",
       "4   0.421084   0.421084  10.896709  10.346092   4.223832   0.390303   \n",
       "5  10.338850   0.655349   7.138202   0.115042   1.362726   0.149050   \n",
       "6   4.124535   0.509908   7.888281   6.685049   0.765714   1.420218   \n",
       "7  10.092655   0.989406  10.486895   9.096087   1.170159   0.500815   \n",
       "8  10.605759   1.232956   8.237365   2.376006   4.479992   1.920087   \n",
       "9   1.971357   1.454085  10.247256  10.665007   1.806557   0.668753   \n",
       "\n",
       "        6121       6157  \n",
       "0  10.523302  10.446166  \n",
       "1  10.523302  10.446166  \n",
       "2   3.183892   3.183892  \n",
       "3   6.938167   6.938167  \n",
       "4   2.033530   2.033530  \n",
       "5  10.398745   1.690993  \n",
       "6  10.531851   0.373156  \n",
       "7   2.105265   0.413589  \n",
       "8   1.315475   1.315475  \n",
       "9  10.559178   0.814330  \n",
       "\n",
       "[10 rows x 213 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for column in df:\n",
    "    df[column] = pd.to_numeric(df[column])\n",
    "\n",
    "df = df.interpolate(method='nearest', axis=1)\n",
    "\n",
    "df = df.fillna(method='backfill')\n",
    "df[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataLoader():\n",
    "    \"\"\"A class for loading and transforming data for the lstm model\"\"\"\n",
    "\n",
    "    def __init__(self, dataframe, split):\n",
    "        print(f\"length of dataframe: {len(dataframe)}\")\n",
    "        i_split = int(len(dataframe) * split)\n",
    "        self.data_train = dataframe.values[:i_split]\n",
    "        print(f\"size of training data: {len(self.data_train)}\")\n",
    "        self.data_test  = dataframe.values[i_split:]\n",
    "        self.len_train  = len(self.data_train)\n",
    "        self.len_test   = len(self.data_test)\n",
    "        self.len_train_windows = None\n",
    "\n",
    "    def get_test_data(self, seq_len, normalise):\n",
    "        '''\n",
    "        Create x, y test data windows\n",
    "        Warning: batch method, not generative, make sure you have enough memory to\n",
    "        load data, otherwise reduce size of the training split.\n",
    "        '''\n",
    "        data_windows = []\n",
    "        for i in range(self.len_test - seq_len):\n",
    "            data_windows.append(self.data_test[i:i+seq_len])\n",
    "\n",
    "        data_windows = np.array(data_windows).astype(float)\n",
    "        data_windows = self.normalise_windows(data_windows, single_window=False) if normalise else data_windows\n",
    "        x = data_windows[:,:-1]\n",
    "        y = data_windows[:,-1:]\n",
    "        \n",
    "        x = torch.from_numpy(np.swapaxes(x,1,2))\n",
    "        y = torch.from_numpy(np.swapaxes(y,1,2))\n",
    "        return x,y\n",
    "\n",
    "    def get_train_data(self, seq_len, normalise):\n",
    "        '''\n",
    "        Create x, y train data windows\n",
    "        Warning: batch method, not generative, make sure you have enough memory to\n",
    "        load data, otherwise use generate_training_window() method.\n",
    "        '''\n",
    "        data_x = []\n",
    "        data_y = []\n",
    "        for i in range(self.len_train - seq_len):\n",
    "            x, y = self._next_window(i, seq_len, normalise)\n",
    "            data_x.append(x)\n",
    "            data_y.append(y)\n",
    "        data_x = np.array(data_x, dtype=np.float32)\n",
    "        data_y = np.array(data_y, dtype=np.float32)\n",
    "        return torch.from_numpy(np.swapaxes(data_x,1,2)), torch.from_numpy(np.swapaxes(data_y,1,2))\n",
    "        \n",
    "\n",
    "    def generate_train_batch(self, seq_len, batch_size, normalise):\n",
    "        '''Yield a generator of training data from filename on given list of cols split for train/test'''\n",
    "        i = 0\n",
    "        while i < (self.len_train - seq_len):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            for b in range(batch_size):\n",
    "                if i >= (self.len_train - seq_len):\n",
    "                    # stop-condition for a smaller final batch if data doesn't divide evenly\n",
    "                    yield np.array(x_batch), np.array(y_batch)\n",
    "                    i = 0\n",
    "                x, y = self._next_window(i, seq_len, normalise)\n",
    "                x_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                i += 1\n",
    "            yield np.array(x_batch, dtype=np.float32), np.array(y_batch, dtype=np.float32)\n",
    "\n",
    "    def _next_window(self, i, seq_len, normalise):\n",
    "        '''Generates the next data window from the given index location i'''\n",
    "        window = self.data_train[i:i+seq_len]\n",
    "        window = self.normalise_windows(window, single_window=True)[0] if normalise else window\n",
    "        x = window[:-1,:]\n",
    "        y = window[-1:,:]\n",
    "        return x, y\n",
    "\n",
    "    def normalise_windows(self, window_data, single_window=False):\n",
    "        '''Normalise window with a base value of zero'''\n",
    "        normalised_data = []\n",
    "        window_data = [window_data] if single_window else window_data\n",
    "        for window in window_data:\n",
    "            normalised_window = []\n",
    "            for col_i in range(window.shape[1]):\n",
    "                normalised_col = [((float(p) / float(window[0, col_i])) - 1) for p in window[:, col_i]]\n",
    "                normalised_window.append(normalised_col)\n",
    "            normalised_window = np.array(normalised_window).T # reshape and transpose array back into original multidimensional format\n",
    "            normalised_data.append(normalised_window)\n",
    "        return np.array(normalised_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "length of dataframe: 144\n",
      "size of training data: 115\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "data = DataLoader(df, 0.8)\n",
    "\n",
    "seq_len=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shapes: torch.Size([105, 213, 9]), torch.Size([105, 213, 1])\n",
      "validation data shapes: torch.Size([19, 213, 9]), torch.Size([19, 213, 1])\n"
     ]
    }
   ],
   "source": [
    "x, y = data.get_train_data(seq_len=10, normalise=False)\n",
    "x_valid, y_valid = data.get_test_data(seq_len=seq_len, normalise=False)\n",
    "\n",
    "print(f\"training data shapes: {x.shape}, {y.shape}\")\n",
    "print(f\"validation data shapes: {x_valid.shape}, {y_valid.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu available: False, used: False\n"
     ]
    }
   ],
   "source": [
    "from test_tube import Experiment \n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "\n",
    "# PyTorch summarywriter with a few bells and whistles    \n",
    "exp = Experiment(save_dir=os.getcwd())\n",
    "\n",
    "# pass in experiment for automatic tensorboard logging.    \n",
    "trainer = Trainer(experiment=exp, max_nb_epochs=1000, train_percent_check=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back=9\n",
    "train=torch.zeros(len(x),213,look_back+1)\n",
    "train[:,:,:look_back]=x\n",
    "train[:,:,look_back:(look_back+1)]=y\n",
    "\n",
    "valid=torch.zeros(len(x_valid),213,look_back+1)\n",
    "valid[:,:,:look_back]=x_valid\n",
    "valid[:,:,look_back:(look_back+1)]=y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = DataLoader(train, batch_size=10, shuffle=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4f45b2ff0ff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mLSTMs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indices' is not defined"
     ]
    }
   ],
   "source": [
    "import imp  \n",
    "import src.tgcn.layers.lstm as l\n",
    "l = imp.reload(l)\n",
    "LSTMs = l.LSTMs\n",
    "model = LSTMs(input_dim=9, hidden_dim=32, data=train, validation_data=valid)\n",
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
